# src/indexing/chroma_indexer.py

from pymongo import MongoClient
from chromadb import PersistentClient
from sentence_transformers import SentenceTransformer
import torch

from src.config import (
    MONGO_CONNECTION_STRING, DB_NAME, RAG_EMBEDDING_MODEL, CHROMA_DB_PATH
)

class ChromaIndexer:
    """
    MongoDBì˜ TM ë°ì´í„°ë¥¼ ì½ì–´ ChromaDBì— ë²¡í„° ì¸ë±ìŠ¤ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
    """
    def __init__(self):
        # MongoDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.mongo_client = MongoClient(MONGO_CONNECTION_STRING)
        self.db = self.mongo_client[DB_NAME]
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.chroma_client = PersistentClient(path=CHROMA_DB_PATH)
        
        # ì„ë² ë”© ëª¨ë¸ ì„¤ì •
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        self.embedding_model = SentenceTransformer(RAG_EMBEDDING_MODEL, device=self.device)
        print(f"âœ… DB ì—°ê²° ë° ì„ë² ë”© ëª¨ë¸({self.device}) ë¡œë“œ ì™„ë£Œ.")

    def _fetch_tm_data(self, tm_collection_name: str) -> list:
        """ì§€ì •ëœ TM ì»¬ë ‰ì…˜ì—ì„œ ëª¨ë“  ë¬¸ì„œë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        print(f"ğŸ”„ MongoDB '{tm_collection_name}' ì»¬ë ‰ì…˜ì—ì„œ ë°ì´í„° ë¡œë“œ ì¤‘...")
        collection = self.db[tm_collection_name]
        data = list(collection.find({}))
        print(f"   - âœ… {len(data)}ê°œì˜ TM ë°ì´í„°ë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        return data

    def create_index(self, lang_suffix: str):
        """
        ì§€ì •ëœ ì–¸ì–´ ìŒì˜ TMì— ëŒ€í•œ ë²¡í„° ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
        ê¸°ì¡´ ì¸ë±ìŠ¤ê°€ ìˆìœ¼ë©´ ë®ì–´ì”ë‹ˆë‹¤.
        """
        tm_collection_name = f"translation_memory_{lang_suffix}"
        chroma_collection_name = f"tm_{lang_suffix}"

        # 1. MongoDBì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        tm_data = self._fetch_tm_data(tm_collection_name)
        if not tm_data:
            print("âš ï¸ ë°ì´í„°ê°€ ì—†ì–´ ì¸ë±ìŠ¤ ìƒì„±ì„ ê±´ë„ˆëœë‹ˆë‹¤.")
            return

        # 2. ChromaDBì— ì €ì¥í•  ë°ì´í„° í˜•ì‹ìœ¼ë¡œ ì¤€ë¹„
        documents = [item['source_text'] for item in tm_data]
        metadatas = [
            {
                "target_text": item['target_text'],
                "page_path": item['page_path'],
                "component_path": item['component_path']
            } for item in tm_data
        ]
        ids = [str(item['_id']) for item in tm_data]
        
        # 3. í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (ë²¡í„° ë³€í™˜)
        print(f"ğŸ¤– '{RAG_EMBEDDING_MODEL}' ëª¨ë¸ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘...")
        embeddings = self.embedding_model.encode(
            documents, 
            show_progress_bar=True,
            batch_size=32
        )
        print("   - âœ… ì„ë² ë”© ìƒì„± ì™„ë£Œ.")

        # 4. ChromaDBì— ì»¬ë ‰ì…˜ ìƒì„± ë° ë°ì´í„° ì €ì¥
        print(f"ğŸ’¾ ChromaDB '{chroma_collection_name}' ì»¬ë ‰ì…˜ì— ë°ì´í„° ì €ì¥ ì¤‘...")
        collection = self.chroma_client.get_or_create_collection(name=chroma_collection_name)
        
        # ChromaDBëŠ” í•œ ë²ˆì— ë§ì€ ì–‘ì„ ë„£ìœ¼ë©´ ì‹¤íŒ¨í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ, ì‘ì€ ë°°ì¹˜ë¡œ ë‚˜ëˆ ì„œ ì €ì¥
        batch_size = 1000
        for i in range(0, len(ids), batch_size):
            collection.add(
                ids=ids[i:i+batch_size],
                embeddings=embeddings[i:i+batch_size],
                metadatas=metadatas[i:i+batch_size],
                documents=documents[i:i+batch_size]
            )
        print(f"   - âœ… ì´ {len(ids)}ê°œ ë²¡í„° ì €ì¥ ì™„ë£Œ.")