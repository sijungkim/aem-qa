# src/processors/translation_pair_generator.py

import numpy as np
from pathlib import Path
from typing import List, Dict
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from src.config import RAG_EMBEDDING_MODEL

class TranslationPairGenerator:
    """ìž„ë² ë”© ìœ ì‚¬ë„ë¥¼ ì‚¬ìš©í•˜ì—¬ ë²ˆì—­ ìŒì„ ìƒì„±í•˜ëŠ” í´ëž˜ìŠ¤"""
    
    def __init__(self, similarity_threshold: float = 0.7):
        self.similarity_threshold = similarity_threshold
        self.embedding_model = None

    def load_embedding_model(self):
        """ìž„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        print("ðŸ¤– ìž„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¤‘...")
        self.embedding_model = SentenceTransformer(RAG_EMBEDDING_MODEL)
        print("âœ… ìž„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ.")

    def generate_pairs(self, source_segments: List[str], target_segments: List[str], 
                      target_pdf_path: str, source_lang: str = 'en', target_lang: str = 'ko') -> List[Dict]:
        """ì†ŒìŠ¤ì™€ íƒ€ê²Ÿ ì–¸ì–´ ì„¸ê·¸ë¨¼íŠ¸ì—ì„œ ë²ˆì—­ ìŒì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if not self.embedding_model:
            self.load_embedding_model()
        
        if not source_segments or not target_segments:
            return []
        
        # ìž„ë² ë”© ê³„ì‚°
        source_embeddings = self._compute_embeddings(source_segments)
        target_embeddings = self._compute_embeddings(target_segments)
        
        # ìœ ì‚¬ë„ ë§¤ì¹­
        return self._match_by_similarity(
            source_segments, target_segments, 
            source_embeddings, target_embeddings,
            target_pdf_path, source_lang, target_lang
        )

    def _compute_embeddings(self, segments: List[str]) -> np.ndarray:
        """í…ìŠ¤íŠ¸ ì„¸ê·¸ë¨¼íŠ¸ë“¤ì˜ ìž„ë² ë”©ì„ ê³„ì‚°í•©ë‹ˆë‹¤."""
        return self.embedding_model.encode(segments, show_progress_bar=False)

    def _match_by_similarity(self, source_segments: List[str], target_segments: List[str],
                           source_embeddings: np.ndarray, target_embeddings: np.ndarray,
                           target_pdf_path: str, source_lang: str, target_lang: str) -> List[Dict]:
        """ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ë²ˆì—­ ìŒì„ ë§¤ì¹­í•©ë‹ˆë‹¤."""
        pairs = []
        target_filename = Path(target_pdf_path).name
        used_target_indices = set()
        
        for i, source_segment in enumerate(source_segments):
            # ìœ ì‚¬ë„ ê³„ì‚°
            similarities = cosine_similarity([source_embeddings[i]], target_embeddings)[0]
            
            # ê°€ìž¥ ë†’ì€ ìœ ì‚¬ë„ ì°¾ê¸°
            best_idx = np.argmax(similarities)
            best_similarity = similarities[best_idx]
            
            # ìž„ê³„ê°’ ì´ìƒì´ê³  ì•„ì§ ì‚¬ìš©ë˜ì§€ ì•Šì€ ê²½ìš°
            if (best_similarity >= self.similarity_threshold and 
                best_idx not in used_target_indices):
                
                pairs.append({
                    'source_text': source_segment.strip(),
                    'target_text': target_segments[best_idx].strip(),
                    'similarity_score': round(float(best_similarity), 4),
                    'source_file': target_filename,
                    'source_lang': source_lang,
                    'target_lang': target_lang,
                    'pair_type': 'pdf_extracted'
                })
                
                used_target_indices.add(best_idx)
        
        return pairs