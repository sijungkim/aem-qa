{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28b6e528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 라이브러리 import 완료\n",
      "🌐 지원 언어 쌍: [('en', 'ko'), ('en', 'ja')]\n",
      "🗄️ Database: aem_qa_system\n",
      "✅ 라이브러리 import 완료\n",
      "📁 CSV 출력 경로: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/3_processed/clean_tm_csv\n"
     ]
    }
   ],
   "source": [
    "# notebooks/10_clean_translation_memory.ipynb\n",
    "\n",
    "# ===================================================================\n",
    "# Cell 1: 라이브러리 import 및 환경 설정\n",
    "# ===================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "# src 폴더를 파이썬 경로에 추가\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "# 프로젝트 모듈들\n",
    "from config import SUPPORTED_LANGUAGE_PAIRS, MONGO_CONNECTION_STRING, DB_NAME, PROCESSED_DIR\n",
    "from processors.tm_cleaner import TMCleaner, clean_all_language_pairs, get_cleaning_stats\n",
    "from pymongo import MongoClient\n",
    "\n",
    "print(\"✅ 라이브러리 import 완료\")\n",
    "print(f\"🌐 지원 언어 쌍: {SUPPORTED_LANGUAGE_PAIRS}\")\n",
    "print(f\"🗄️ Database: {DB_NAME}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# CSV 출력 디렉토리 확인/생성\n",
    "csv_output_dir = os.path.join(PROCESSED_DIR, \"clean_tm_csv\")\n",
    "os.makedirs(csv_output_dir, exist_ok=True)\n",
    "\n",
    "print(\"✅ 라이브러리 import 완료\")\n",
    "print(f\"📁 CSV 출력 경로: {csv_output_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 2: Raw TM 현황 확인\n",
    "# ===================================================================\n",
    "\n",
    "def preview_raw_tm_samples(lang_suffix: str, limit: int = 5):\n",
    "    \"\"\"Raw TM 샘플 미리보기\"\"\"\n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    raw_tm_collection = db[f\"translation_memory_{lang_suffix}\"]\n",
    "    \n",
    "    total_count = raw_tm_collection.count_documents({})\n",
    "    print(f\"🔍 [{lang_suffix}] Raw TM 현황: 총 {total_count:,}개\")\n",
    "    \n",
    "    if total_count == 0:\n",
    "        print(\"   ⚠️ Raw TM 데이터가 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"   📋 샘플 {limit}개:\")\n",
    "    samples = list(raw_tm_collection.find({}).limit(limit))\n",
    "    \n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        source = sample.get('source_text', '')[:80]\n",
    "        target = sample.get('target_text', '')[:80]\n",
    "        print(f\"   {i}. Source: '{source}{'...' if len(sample.get('source_text', '')) > 80 else ''}'\")\n",
    "        print(f\"      Target: '{target}{'...' if len(sample.get('target_text', '')) > 80 else ''}'\")\n",
    "        print(f\"      Page: {sample.get('page_path', 'N/A')}\")\n",
    "        print()\n",
    "\n",
    "# 현재 Raw TM 현황 확인\n",
    "print(\"📊 Raw TM 현황 확인:\")\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    print(f\"\\n--- {source_lang.upper()}-{target_lang.upper()} ---\")\n",
    "    preview_raw_tm_samples(lang_suffix, limit=3)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf26dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 3: 단일 언어 쌍 정제 (EN-KO)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"🇰🇷 한국어 번역 메모리 정제 시작\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# TM Cleaner 초기화\n",
    "cleaner = TMCleaner()\n",
    "\n",
    "# EN-KO TM 정제 실행\n",
    "ko_result = cleaner.clean_translation_memory(\"en_ko\")\n",
    "\n",
    "print(f\"\\n✅ 한국어 TM 정제 완료!\")\n",
    "if ko_result.get(\"status\") != \"no_data\":\n",
    "    print(f\"   입력: {ko_result.get('input_count', 0):,}개\")\n",
    "    print(f\"   출력: {ko_result.get('output_count', 0):,}개\")\n",
    "    print(f\"   효율: {ko_result.get('cleaning_efficiency', 0):.1%}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28391071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 4: 모든 언어 쌍 정제\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🌐 모든 언어 쌍 번역 메모리 정제\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 모든 언어 쌍 일괄 정제\n",
    "all_results = clean_all_language_pairs()\n",
    "\n",
    "# 전체 결과 요약\n",
    "print(\"\\n📊 전체 정제 결과 요약:\")\n",
    "print(\"-\" * 50)\n",
    "for lang_suffix, result in all_results.items():\n",
    "    if result.get(\"status\") == \"error\":\n",
    "        print(f\"❌ {lang_suffix}: {result.get('error', 'Unknown error')}\")\n",
    "    elif result.get(\"status\") == \"no_data\":\n",
    "        print(f\"⚠️ {lang_suffix}: Raw TM 데이터 없음\")\n",
    "    else:\n",
    "        input_count = result.get('input_count', 0)\n",
    "        output_count = result.get('output_count', 0)\n",
    "        efficiency = result.get('cleaning_efficiency', 0)\n",
    "        print(f\"✅ {lang_suffix}: {input_count:,} → {output_count:,} ({efficiency:.1%})\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d46937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 5: 정제 결과 비교 및 품질 확인\n",
    "# ===================================================================\n",
    "\n",
    "def compare_before_after(lang_suffix: str, limit: int = 3):\n",
    "    \"\"\"정제 전후 비교\"\"\"\n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    clean_tm_collection = db[f\"clean_translation_memory_{lang_suffix}\"]\n",
    "    \n",
    "    count = clean_tm_collection.count_documents({})\n",
    "    if count == 0:\n",
    "        print(f\"⚠️ [{lang_suffix}] 정제된 TM이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    print(f\"🔍 [{lang_suffix}] 정제 전후 비교 (총 {count:,}개 중 {limit}개 샘플):\")\n",
    "    samples = list(clean_tm_collection.find({}).limit(limit))\n",
    "    \n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"\\n--- 샘플 {i} ---\")\n",
    "        print(f\"✨ 정제 후:\")\n",
    "        print(f\"   Source: '{sample.get('source_text', '')}'\")\n",
    "        print(f\"   Target: '{sample.get('target_text', '')}'\")\n",
    "        print(f\"🗑️ 원본:\")\n",
    "        print(f\"   Source: '{sample.get('original_source_text', '')[:100]}...'\")\n",
    "        print(f\"   Target: '{sample.get('original_target_text', '')[:100]}...'\")\n",
    "        print(f\"📊 품질: {sample.get('quality_score', 'N/A'):.2f} ({sample.get('text_type', 'N/A')})\")\n",
    "\n",
    "print(\"📋 정제 결과 품질 확인:\")\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    print(f\"\\n--- {source_lang.upper()}-{target_lang.upper()} ---\")\n",
    "    compare_before_after(lang_suffix, limit=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e25148b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 6: 정제 통계 상세 분석\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📈 정제 통계 상세 분석\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# 각 언어 쌍의 상세 통계\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    stats = get_cleaning_stats(lang_suffix)\n",
    "    \n",
    "    if not stats:\n",
    "        print(f\"⚠️ {source_lang.upper()}-{target_lang.upper()}: 통계 데이터 없음\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n📊 {source_lang.upper()}-{target_lang.upper()} 상세 통계:\")\n",
    "    print(f\"   🕐 정제 시간: {stats['cleaning_date']}\")\n",
    "    print(f\"   📈 효율성: {stats['cleaning_efficiency']:.1%}\")\n",
    "    print(f\"   📥 입력: {stats['input_count']:,}개\")\n",
    "    print(f\"   📤 출력: {stats['output_count']:,}개\")\n",
    "    print(f\"   🗑️ 제거: {stats['removed_count']:,}개\")\n",
    "    \n",
    "    # 제거 이유 Top 5\n",
    "    print(f\"   🔍 주요 제거 이유:\")\n",
    "    removal_reasons = sorted(stats['removal_reasons'].items(), key=lambda x: x[1], reverse=True)\n",
    "    for reason, count in removal_reasons[:5]:\n",
    "        percentage = count / stats['input_count'] * 100\n",
    "        print(f\"     - {reason}: {count:,}개 ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 품질 분포\n",
    "    print(f\"   🏆 품질 분포:\")\n",
    "    quality_dist = stats['quality_distribution']\n",
    "    for tier in ['high', 'medium', 'low', 'very_low']:\n",
    "        count = quality_dist.get(tier, 0)\n",
    "        if count > 0:\n",
    "            percentage = count / stats['output_count'] * 100\n",
    "            print(f\"     - {tier}: {count:,}개 ({percentage:.1f}%)\")\n",
    "    \n",
    "    # 텍스트 유형 Top 3\n",
    "    print(f\"   📝 주요 텍스트 유형:\")\n",
    "    text_types = sorted(stats['text_types'].items(), key=lambda x: x[1], reverse=True)\n",
    "    for text_type, count in text_types[:3]:\n",
    "        percentage = count / stats['output_count'] * 100\n",
    "        print(f\"     - {text_type}: {count:,}개 ({percentage:.1f}%)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489de40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 7: MongoDB 컬렉션 현황 확인\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🗄️ MongoDB 컬렉션 현황\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# MongoDB 연결 및 컬렉션 목록 조회\n",
    "client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "db = client[DB_NAME]\n",
    "collections = db.list_collection_names()\n",
    "\n",
    "# TM 관련 컬렉션 분류\n",
    "raw_tm_collections = [c for c in collections if c.startswith(\"translation_memory_\") and not c.startswith(\"clean_\")]\n",
    "clean_tm_collections = [c for c in collections if c.startswith(\"clean_translation_memory_\")]\n",
    "stats_collections = [c for c in collections if c.startswith(\"tm_cleaning_stats_\")]\n",
    "\n",
    "print(f\"📋 TM 관련 컬렉션 현황:\")\n",
    "print(f\"   📄 Raw TM: {len(raw_tm_collections)}개\")\n",
    "print(f\"   ✨ Clean TM: {len(clean_tm_collections)}개\")\n",
    "print(f\"   📊 통계: {len(stats_collections)}개\")\n",
    "\n",
    "# 컬렉션별 문서 수와 저장 공간 정보\n",
    "print(f\"\\n📊 컬렉션별 상세 정보:\")\n",
    "print(f\"{'타입':<12} {'컬렉션명':<35} {'문서수':<12} {'상태'}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for collection_name in sorted(raw_tm_collections + clean_tm_collections + stats_collections):\n",
    "    count = db[collection_name].count_documents({})\n",
    "    \n",
    "    if collection_name.startswith(\"translation_memory_\"):\n",
    "        col_type = \"Raw TM\"\n",
    "    elif collection_name.startswith(\"clean_translation_memory_\"):\n",
    "        col_type = \"Clean TM\"\n",
    "    else:\n",
    "        col_type = \"통계\"\n",
    "    \n",
    "    status = \"✅ 정상\" if count > 0 else \"⚠️ 비어있음\"\n",
    "    print(f\"{col_type:<12} {collection_name:<35} {count:>8,}개 {status}\")\n",
    "\n",
    "# 정제 효율성 요약\n",
    "print(f\"\\n📈 전체 정제 효율성 요약:\")\n",
    "total_raw = sum(db[c].count_documents({}) for c in raw_tm_collections)\n",
    "total_clean = sum(db[c].count_documents({}) for c in clean_tm_collections)\n",
    "\n",
    "if total_raw > 0:\n",
    "    overall_efficiency = total_clean / total_raw\n",
    "    print(f\"   전체 Raw TM: {total_raw:,}개\")\n",
    "    print(f\"   전체 Clean TM: {total_clean:,}개\")\n",
    "    print(f\"   전체 효율성: {overall_efficiency:.1%}\")\n",
    "    print(f\"   제거된 노이즈: {total_raw - total_clean:,}개\")\n",
    "else:\n",
    "    print(\"   ⚠️ Raw TM 데이터가 없습니다.\")\n",
    "\n",
    "print(\"\\n✅ TM 정제 작업 및 분석 완료!\")\n",
    "print(\"💡 이제 clean_translation_memory_* 컬렉션을 사용하여 AI 검색 인덱스를 업데이트하세요.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7687e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 8: 정제된 TM 샘플 확인 (최종 검증)\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"🔍 정제된 TM 최종 검증\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def verify_clean_tm_quality(lang_suffix: str, sample_size: int = 10):\n",
    "    \"\"\"정제된 TM 품질 검증\"\"\"\n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    clean_tm_collection = db[f\"clean_translation_memory_{lang_suffix}\"]\n",
    "    \n",
    "    print(f\"🔍 [{lang_suffix}] 정제된 TM 품질 검증:\")\n",
    "    \n",
    "    # 랜덤 샘플 추출\n",
    "    pipeline = [{\"$sample\": {\"size\": sample_size}}]\n",
    "    samples = list(clean_tm_collection.aggregate(pipeline))\n",
    "    \n",
    "    if not samples:\n",
    "        print(\"   ⚠️ 정제된 TM이 없습니다.\")\n",
    "        return\n",
    "    \n",
    "    # 품질 검증\n",
    "    high_quality = 0\n",
    "    has_meaningful_text = 0\n",
    "    proper_length = 0\n",
    "    \n",
    "    print(f\"   📋 {len(samples)}개 샘플 검증 결과:\")\n",
    "    \n",
    "    for sample in samples:\n",
    "        source = sample.get('source_text', '')\n",
    "        target = sample.get('target_text', '')\n",
    "        quality = sample.get('quality_score', 0)\n",
    "        \n",
    "        # 고품질 체크\n",
    "        if quality >= 0.5:\n",
    "            high_quality += 1\n",
    "        \n",
    "        # 의미있는 텍스트 체크\n",
    "        if len(source.strip()) > 2 and len(target.strip()) > 2:\n",
    "            has_meaningful_text += 1\n",
    "        \n",
    "        # 적절한 길이 체크\n",
    "        if 2 <= len(source.split()) <= 100:\n",
    "            proper_length += 1\n",
    "    \n",
    "    print(f\"     ✅ 고품질 (≥0.5): {high_quality}/{len(samples)} ({high_quality/len(samples)*100:.1f}%)\")\n",
    "    print(f\"     ✅ 의미있는 텍스트: {has_meaningful_text}/{len(samples)} ({has_meaningful_text/len(samples)*100:.1f}%)\")\n",
    "    print(f\"     ✅ 적절한 길이: {proper_length}/{len(samples)} ({proper_length/len(samples)*100:.1f}%)\")\n",
    "    \n",
    "    # 우수 샘플 3개 표시\n",
    "    high_quality_samples = [s for s in samples if s.get('quality_score', 0) >= 0.7]\n",
    "    if high_quality_samples:\n",
    "        print(f\"   🏆 우수 품질 샘플:\")\n",
    "        for i, sample in enumerate(high_quality_samples[:3], 1):\n",
    "            print(f\"     {i}. '{sample.get('source_text', '')}' → '{sample.get('target_text', '')}'\")\n",
    "            print(f\"        (품질: {sample.get('quality_score', 0):.2f}, 유형: {sample.get('text_type', 'N/A')})\")\n",
    "\n",
    "# 각 언어 쌍 검증\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    verify_clean_tm_quality(lang_suffix, sample_size=20)\n",
    "    print()\n",
    "\n",
    "print(\"🎉 TM 정제 프로세스 완료!\")\n",
    "print(\"📝 다음 단계: ChromaDB 인덱스를 정제된 TM으로 업데이트\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8afd7371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 2: Clean TM을 CSV로 내보내기 함수\n",
    "# ===================================================================\n",
    "\n",
    "def export_clean_tm_to_csv(lang_suffix: str, include_metadata: bool = True) -> str:\n",
    "    \"\"\"정제된 TM을 CSV 파일로 내보내기\"\"\"\n",
    "    \n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    clean_tm_collection = db[f\"clean_translation_memory_{lang_suffix}\"]\n",
    "    \n",
    "    print(f\"📤 [{lang_suffix}] Clean TM CSV 내보내기 시작...\")\n",
    "    \n",
    "    # 데이터 조회\n",
    "    cursor = clean_tm_collection.find({})\n",
    "    docs = list(cursor)\n",
    "    \n",
    "    if not docs:\n",
    "        print(f\"   ⚠️ {lang_suffix} Clean TM 데이터가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"   📊 총 {len(docs):,}개 문서 로드 완료\")\n",
    "    \n",
    "    # DataFrame 생성용 데이터 준비\n",
    "    csv_data = []\n",
    "    \n",
    "    for doc in docs:\n",
    "        row = {\n",
    "            'source_text': doc.get('source_text', ''),\n",
    "            'target_text': doc.get('target_text', ''),\n",
    "            'quality_score': doc.get('quality_score', 0),\n",
    "            'text_type': doc.get('text_type', ''),\n",
    "            'word_count_source': doc.get('word_count_source', 0),\n",
    "            'word_count_target': doc.get('word_count_target', 0),\n",
    "        }\n",
    "        \n",
    "        if include_metadata:\n",
    "            row.update({\n",
    "                'page_path': doc.get('page_path', ''),\n",
    "                'component_path': doc.get('component_path', ''),\n",
    "                'component_type': doc.get('component_type', ''),\n",
    "                'version_name_source': doc.get('version_name', ''),  # 소스 버전\n",
    "                'version_number': doc.get('version_number', 1),\n",
    "                'original_source_text': doc.get('original_source_text', ''),\n",
    "                'original_target_text': doc.get('original_target_text', ''),\n",
    "                'cleaning_method': doc.get('cleaning_method', ''),\n",
    "                'cleaned_at': doc.get('cleaned_at', '')\n",
    "            })\n",
    "        \n",
    "        csv_data.append(row)\n",
    "    \n",
    "    # DataFrame 생성\n",
    "    df = pd.DataFrame(csv_data)\n",
    "    \n",
    "    # 품질 순으로 정렬\n",
    "    df = df.sort_values(['quality_score', 'word_count_source'], ascending=[False, False])\n",
    "    \n",
    "    # CSV 파일명 생성\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    metadata_suffix = \"_with_metadata\" if include_metadata else \"_simple\"\n",
    "    filename = f\"clean_tm_{lang_suffix}{metadata_suffix}_{timestamp}.csv\"\n",
    "    filepath = os.path.join(csv_output_dir, filename)\n",
    "    \n",
    "    # CSV 저장\n",
    "    df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"   ✅ CSV 저장 완료: {filename}\")\n",
    "    print(f\"   📊 컬럼 수: {len(df.columns)}개\")\n",
    "    print(f\"   📋 행 수: {len(df):,}개\")\n",
    "    print(f\"   💾 파일 크기: {os.path.getsize(filepath) / 1024 / 1024:.1f} MB\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "def export_tm_statistics_to_csv() -> str:\n",
    "    \"\"\"TM 정제 통계를 CSV로 내보내기\"\"\"\n",
    "    \n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    \n",
    "    print(\"📊 TM 정제 통계 CSV 내보내기...\")\n",
    "    \n",
    "    stats_data = []\n",
    "    \n",
    "    for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "        lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "        stats_collection = db[f\"tm_cleaning_stats_{lang_suffix}\"]\n",
    "        \n",
    "        stats_doc = stats_collection.find_one({}, sort=[(\"cleaning_date\", -1)])\n",
    "        \n",
    "        if stats_doc:\n",
    "            # 제거 이유를 개별 컬럼으로 분리\n",
    "            removal_reasons = stats_doc.get('removal_reasons', {})\n",
    "            quality_dist = stats_doc.get('quality_distribution', {})\n",
    "            text_types = stats_doc.get('text_types', {})\n",
    "            \n",
    "            row = {\n",
    "                'language_pair': lang_suffix,\n",
    "                'source_language': source_lang,\n",
    "                'target_language': target_lang,\n",
    "                'cleaning_date': stats_doc.get('cleaning_date', ''),\n",
    "                'input_count': stats_doc.get('input_count', 0),\n",
    "                'output_count': stats_doc.get('output_count', 0),\n",
    "                'removed_count': stats_doc.get('removed_count', 0),\n",
    "                'cleaning_efficiency': stats_doc.get('cleaning_efficiency', 0),\n",
    "                \n",
    "                # 제거 이유별 카운트\n",
    "                'removed_empty_source_text': removal_reasons.get('empty_source_text', 0),\n",
    "                'removed_empty_target_text': removal_reasons.get('empty_target_text', 0),\n",
    "                'removed_source_too_short': removal_reasons.get('source_too_short', 0),\n",
    "                'removed_target_too_short': removal_reasons.get('target_too_short', 0),\n",
    "                'removed_jcr_sling_properties': removal_reasons.get('jcr_sling_properties', 0),\n",
    "                'removed_no_meaningful_chars': removal_reasons.get('source_no_meaningful_chars', 0) + removal_reasons.get('target_no_meaningful_chars', 0),\n",
    "                'removed_only_numbers_symbols': removal_reasons.get('source_only_numbers_symbols', 0) + removal_reasons.get('target_only_numbers_symbols', 0),\n",
    "                \n",
    "                # 품질 분포\n",
    "                'quality_high': quality_dist.get('high', 0),\n",
    "                'quality_medium': quality_dist.get('medium', 0),\n",
    "                'quality_low': quality_dist.get('low', 0),\n",
    "                'quality_very_low': quality_dist.get('very_low', 0),\n",
    "                \n",
    "                # 텍스트 유형 (주요 3개)\n",
    "                'text_type_title': text_types.get('title', 0),\n",
    "                'text_type_sentence': text_types.get('sentence', 0),\n",
    "                'text_type_plain_text': text_types.get('plain_text', 0),\n",
    "                'text_type_others': sum(text_types.values()) - text_types.get('title', 0) - text_types.get('sentence', 0) - text_types.get('plain_text', 0)\n",
    "            }\n",
    "            \n",
    "            stats_data.append(row)\n",
    "    \n",
    "    if not stats_data:\n",
    "        print(\"   ⚠️ 정제 통계 데이터가 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # DataFrame 생성 및 저장\n",
    "    df = pd.DataFrame(stats_data)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f\"tm_cleaning_statistics_{timestamp}.csv\"\n",
    "    filepath = os.path.join(csv_output_dir, filename)\n",
    "    \n",
    "    df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"   ✅ 통계 CSV 저장 완료: {filename}\")\n",
    "    print(f\"   📊 언어 쌍 수: {len(df)}개\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c2fa757",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# Cell 3: 품질별 샘플 CSV 생성\n",
    "# ===================================================================\n",
    "\n",
    "def export_quality_samples_to_csv(lang_suffix: str, samples_per_tier: int = 50) -> str:\n",
    "    \"\"\"품질 등급별 샘플을 CSV로 내보내기\"\"\"\n",
    "    \n",
    "    client = MongoClient(MONGO_CONNECTION_STRING)\n",
    "    db = client[DB_NAME]\n",
    "    clean_tm_collection = db[f\"clean_translation_memory_{lang_suffix}\"]\n",
    "    \n",
    "    print(f\"🏆 [{lang_suffix}] 품질별 샘플 CSV 생성...\")\n",
    "    \n",
    "    quality_tiers = ['high', 'medium', 'low', 'very_low']\n",
    "    all_samples = []\n",
    "    \n",
    "    for tier in quality_tiers:\n",
    "        print(f\"   🔍 {tier} 품질 샘플 추출 중...\")\n",
    "        \n",
    "        # 해당 품질 등급의 문서들을 무작위로 샘플링\n",
    "        pipeline = [\n",
    "            {\"$match\": {\"quality_score\": {\"$exists\": True}}},\n",
    "            {\"$addFields\": {\n",
    "                \"quality_tier\": {\n",
    "                    \"$switch\": {\n",
    "                        \"branches\": [\n",
    "                            {\"case\": {\"$gte\": [\"$quality_score\", 0.8]}, \"then\": \"high\"},\n",
    "                            {\"case\": {\"$gte\": [\"$quality_score\", 0.5]}, \"then\": \"medium\"},\n",
    "                            {\"case\": {\"$gte\": [\"$quality_score\", 0.2]}, \"then\": \"low\"}\n",
    "                        ],\n",
    "                        \"default\": \"very_low\"\n",
    "                    }\n",
    "                }\n",
    "            }},\n",
    "            {\"$match\": {\"quality_tier\": tier}},\n",
    "            {\"$sample\": {\"size\": samples_per_tier}},\n",
    "            {\"$sort\": {\"quality_score\": -1}}\n",
    "        ]\n",
    "        \n",
    "        samples = list(clean_tm_collection.aggregate(pipeline))\n",
    "        \n",
    "        for sample in samples:\n",
    "            sample_data = {\n",
    "                'quality_tier': tier,\n",
    "                'quality_score': sample.get('quality_score', 0),\n",
    "                'source_text': sample.get('source_text', ''),\n",
    "                'target_text': sample.get('target_text', ''),\n",
    "                'text_type': sample.get('text_type', ''),\n",
    "                'word_count_source': sample.get('word_count_source', 0),\n",
    "                'word_count_target': sample.get('word_count_target', 0),\n",
    "                'page_path': sample.get('page_path', ''),\n",
    "                'component_type': sample.get('component_type', ''),\n",
    "                'original_source_text': sample.get('original_source_text', '')[:200],  # 원본은 200자만\n",
    "                'original_target_text': sample.get('original_target_text', '')[:200]   # 원본은 200자만\n",
    "            }\n",
    "            all_samples.append(sample_data)\n",
    "        \n",
    "        print(f\"     ✅ {len(samples)}개 샘플 추출\")\n",
    "    \n",
    "    if not all_samples:\n",
    "        print(f\"   ⚠️ {lang_suffix} 품질 샘플이 없습니다.\")\n",
    "        return None\n",
    "    \n",
    "    # DataFrame 생성 및 저장\n",
    "    df = pd.DataFrame(all_samples)\n",
    "    \n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    filename = f\"clean_tm_quality_samples_{lang_suffix}_{timestamp}.csv\"\n",
    "    filepath = os.path.join(csv_output_dir, filename)\n",
    "    \n",
    "    df.to_csv(filepath, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"   ✅ 품질 샘플 CSV 저장 완료: {filename}\")\n",
    "    print(f\"   📊 총 샘플 수: {len(df):,}개\")\n",
    "    \n",
    "    # 품질별 분포 출력\n",
    "    tier_counts = df['quality_tier'].value_counts()\n",
    "    for tier in quality_tiers:\n",
    "        count = tier_counts.get(tier, 0)\n",
    "        print(f\"     - {tier}: {count}개\")\n",
    "    \n",
    "    return filepath\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1183bef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 정제된 TM CSV 내보내기 시작\n",
      "==================================================\n",
      "\n",
      "📤 EN-KO TM 내보내기...\n",
      "📤 [en_ko] Clean TM CSV 내보내기 시작...\n",
      "   📊 총 13,743개 문서 로드 완료\n",
      "   ✅ CSV 저장 완료: clean_tm_en_ko_with_metadata_20250812_111944.csv\n",
      "   📊 컬럼 수: 15개\n",
      "   📋 행 수: 13,743개\n",
      "   💾 파일 크기: 12.0 MB\n",
      "📤 [en_ko] Clean TM CSV 내보내기 시작...\n",
      "   📊 총 13,743개 문서 로드 완료\n",
      "   ✅ CSV 저장 완료: clean_tm_en_ko_simple_20250812_111944.csv\n",
      "   📊 컬럼 수: 6개\n",
      "   📋 행 수: 13,743개\n",
      "   💾 파일 크기: 4.3 MB\n",
      "\n",
      "📤 EN-JA TM 내보내기...\n",
      "📤 [en_ja] Clean TM CSV 내보내기 시작...\n",
      "   📊 총 14,492개 문서 로드 완료\n",
      "   ✅ CSV 저장 완료: clean_tm_en_ja_with_metadata_20250812_111945.csv\n",
      "   📊 컬럼 수: 15개\n",
      "   📋 행 수: 14,492개\n",
      "   💾 파일 크기: 14.0 MB\n",
      "📤 [en_ja] Clean TM CSV 내보내기 시작...\n",
      "   📊 총 14,492개 문서 로드 완료\n",
      "   ✅ CSV 저장 완료: clean_tm_en_ja_simple_20250812_111945.csv\n",
      "   📊 컬럼 수: 6개\n",
      "   📋 행 수: 14,492개\n",
      "   💾 파일 크기: 5.1 MB\n",
      "\n",
      "📊 정제 통계 내보내기...\n",
      "📊 TM 정제 통계 CSV 내보내기...\n",
      "   ✅ 통계 CSV 저장 완료: tm_cleaning_statistics_20250812_111945.csv\n",
      "   📊 언어 쌍 수: 2개\n",
      "\n",
      "✅ CSV 내보내기 완료!\n",
      "📁 출력 경로: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/3_processed/clean_tm_csv\n",
      "📄 생성된 파일: 5개\n",
      "   - clean_tm_en_ko_with_metadata_20250812_111944.csv (12.0 MB)\n",
      "   - clean_tm_en_ko_simple_20250812_111944.csv (4.3 MB)\n",
      "   - clean_tm_en_ja_with_metadata_20250812_111945.csv (14.0 MB)\n",
      "   - clean_tm_en_ja_simple_20250812_111945.csv (5.1 MB)\n",
      "   - tm_cleaning_statistics_20250812_111945.csv (0.0 MB)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Cell 4: 전체 Clean TM CSV 내보내기 실행\n",
    "# ===================================================================\n",
    "\n",
    "print(\"🚀 정제된 TM CSV 내보내기 시작\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "exported_files = []\n",
    "\n",
    "# 1. 각 언어 쌍의 Clean TM 내보내기\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    \n",
    "    print(f\"\\n📤 {source_lang.upper()}-{target_lang.upper()} TM 내보내기...\")\n",
    "    \n",
    "    # 메타데이터 포함 버전\n",
    "    filepath_full = export_clean_tm_to_csv(lang_suffix, include_metadata=True)\n",
    "    if filepath_full:\n",
    "        exported_files.append(filepath_full)\n",
    "    \n",
    "    # 간단 버전 (번역쌍 + 품질 정보만)\n",
    "    filepath_simple = export_clean_tm_to_csv(lang_suffix, include_metadata=False)\n",
    "    if filepath_simple:\n",
    "        exported_files.append(filepath_simple)\n",
    "\n",
    "# 2. 정제 통계 내보내기\n",
    "print(f\"\\n📊 정제 통계 내보내기...\")\n",
    "stats_filepath = export_tm_statistics_to_csv()\n",
    "if stats_filepath:\n",
    "    exported_files.append(stats_filepath)\n",
    "\n",
    "print(f\"\\n✅ CSV 내보내기 완료!\")\n",
    "print(f\"📁 출력 경로: {csv_output_dir}\")\n",
    "print(f\"📄 생성된 파일: {len(exported_files)}개\")\n",
    "\n",
    "for filepath in exported_files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
    "    print(f\"   - {filename} ({size_mb:.1f} MB)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4028f8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "🏆 품질별 샘플 CSV 생성\n",
      "==================================================\n",
      "\n",
      "🔍 EN-KO 품질 샘플...\n",
      "🏆 [en_ko] 품질별 샘플 CSV 생성...\n",
      "   🔍 high 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 medium 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 low 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 very_low 품질 샘플 추출 중...\n",
      "     ✅ 0개 샘플 추출\n",
      "   ✅ 품질 샘플 CSV 저장 완료: clean_tm_quality_samples_en_ko_20250812_112206.csv\n",
      "   📊 총 샘플 수: 90개\n",
      "     - high: 30개\n",
      "     - medium: 30개\n",
      "     - low: 30개\n",
      "     - very_low: 0개\n",
      "\n",
      "🔍 EN-JA 품질 샘플...\n",
      "🏆 [en_ja] 품질별 샘플 CSV 생성...\n",
      "   🔍 high 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 medium 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 low 품질 샘플 추출 중...\n",
      "     ✅ 30개 샘플 추출\n",
      "   🔍 very_low 품질 샘플 추출 중...\n",
      "     ✅ 0개 샘플 추출\n",
      "   ✅ 품질 샘플 CSV 저장 완료: clean_tm_quality_samples_en_ja_20250812_112206.csv\n",
      "   📊 총 샘플 수: 90개\n",
      "     - high: 30개\n",
      "     - medium: 30개\n",
      "     - low: 30개\n",
      "     - very_low: 0개\n",
      "\n",
      "✅ 품질 샘플 CSV 생성 완료!\n",
      "   - clean_tm_quality_samples_en_ko_20250812_112206.csv (0.0 MB)\n",
      "   - clean_tm_quality_samples_en_ja_20250812_112206.csv (0.2 MB)\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Cell 5: 품질별 샘플 CSV 생성\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"🏆 품질별 샘플 CSV 생성\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "sample_files = []\n",
    "\n",
    "for source_lang, target_lang in SUPPORTED_LANGUAGE_PAIRS:\n",
    "    lang_suffix = f\"{source_lang}_{target_lang}\"\n",
    "    \n",
    "    print(f\"\\n🔍 {source_lang.upper()}-{target_lang.upper()} 품질 샘플...\")\n",
    "    \n",
    "    sample_filepath = export_quality_samples_to_csv(lang_suffix, samples_per_tier=30)\n",
    "    if sample_filepath:\n",
    "        sample_files.append(sample_filepath)\n",
    "\n",
    "print(f\"\\n✅ 품질 샘플 CSV 생성 완료!\")\n",
    "for filepath in sample_files:\n",
    "    filename = os.path.basename(filepath)\n",
    "    size_mb = os.path.getsize(filepath) / 1024 / 1024\n",
    "    print(f\"   - {filename} ({size_mb:.1f} MB)\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63e1ec1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "👀 생성된 CSV 파일 미리보기\n",
      "==================================================\n",
      "\n",
      "📄 clean_tm_en_ko_with_metadata_20250812_111944.csv\n",
      "   📊 크기: 13,743행 × 15열\n",
      "   📋 컬럼: source_text, target_text, quality_score, text_type, word_count_source...\n",
      "   🔍 처음 5행:\n",
      "     1. [1.0] 'Circulating tumor DNA (ctDNA) may represent a very...' → '순환 종양 DNA(circulating tumor DNA, ctDNA)는 차세대 염기서열분...'\n",
      "     2. [1.0] 'Putting people first and doing the right thing are...' → '옳은 일을 하는 것은 Illumina의 정체성과 Illumina 사업의 핵심입니다. Ill...'\n",
      "     3. [1.0] 'Compute pricing rates for Illumina Connected Analy...' → 'Illumina Connected Analytics의 컴퓨팅 가격 책정 비율은 ICA 도움...'\n",
      "     4. [1.0] 'If you currently own a HiSeq 2500, HiSeq 3000/4000...' → '현재 HiSeq 2500, HiSeq 3000/4000 또는 HiSeq X를 소유하고 있다...'\n",
      "     5. [1.0] 'Run the RNA-Seq workflow (FASTQ only) on the MiSeq...' → 'MiSeq System에서 RNA-Seq 워크플로우(FASTQ만 해당)를 실행하고 Base...'\n",
      "\n",
      "📄 clean_tm_en_ja_with_metadata_20250812_111945.csv\n",
      "   📊 크기: 14,492행 × 15열\n",
      "   📋 컬럼: source_text, target_text, quality_score, text_type, word_count_source...\n",
      "   🔍 처음 5행:\n",
      "     1. [1.0] 'To prepare targeted NGS libraries, Illumina DNA Pr...' → 'Illumina DNA Prep with Enrichment DxでターゲットNGSライブラリ...'\n",
      "     2. [1.0] 'TruSeq DNA PCR-Free with Single Indexes supports 2...' → 'TruSeq DNA PCR-Free with Single Indexesは、ロースループット（...'\n",
      "     3. [1.0] 'Illumina RNA Prep with Enrichment, (L) Tagmentatio...' → 'Illumina RNA Prep with Enrichment, (L) Tagmentatio...'\n",
      "     4. [1.0] 'The oncoReveal Multi-Cancer with CNV and RNA Fusio...' → 'oncoReveal Multi-Cancer with CNV and RNA Fusion Pa...'\n",
      "     5. [1.0] 'Buffer cartridges and library tubes are sold separ...' → 'バッファーカートリッジおよびライブラリーチューブは、試薬キットとは別売りです。  NovaSeq 6...'\n",
      "\n",
      "📄 clean_tm_quality_samples_en_ko_20250812_112206.csv\n",
      "   📊 크기: 90행 × 11열\n",
      "   📋 컬럼: quality_tier, quality_score, source_text, target_text, text_type...\n",
      "   🔍 처음 5행:\n",
      "     1. [1.0] 'The BaseSpace Sequence Hub workflow tracks samples...' → 'BaseSpace Sequence Hub 워크플로우는 라이브러리 준비에서 데이터 분석까지 ...'\n",
      "     2. [1.0] 'Scale up or down depending on your storage needs—w...' → '하드웨어 유지 관리 또는 IT 지원 없이 스토리지 요구 사항에 따라 규모를 확장 또는 축소...'\n",
      "     3. [1.0] 'Intuitive, streamlined user interface Plan and sta...' → '직관적이고 간소화된 사용자 인터페이스 Illumina Run Manager를 사용하여 시퀀...'\n",
      "     4. [1.0] 'Illumina has established an integration process to...' → 'Illumina는 통합 프로세스를 구축하였으며 통합이 처음부터 끝까지 철저하게 시험될 수 ...'\n",
      "     5. [1.0] 'Transparent logic. Every AI hypothesis is backed b...' → '투명한 논리. 모든 AI 가설은 문헌과 데이터베이스 출처로 뒷받침됩니다. ...'\n",
      "\n",
      "📄 clean_tm_quality_samples_en_ja_20250812_112206.csv\n",
      "   📊 크기: 90행 × 11열\n",
      "   📋 컬럼: quality_tier, quality_score, source_text, target_text, text_type...\n",
      "   🔍 처음 5행:\n",
      "     1. [1.0] 'Test results, supported by an expertly curated Kno...' → 'Test results, supported by an expertly curated Kno...'\n",
      "     2. [0.8] 'Supports a low input DNA sample requirement of 100...' → '100～200 ng程度の少量のDNAサンプルで、数百万箇所の遺伝子座を解析可能。...'\n",
      "     3. [0.8] 'Targeted NGS Empowers Genetic Testing...' → 'Targeted NGS Empowers Genetic Testing...'\n",
      "     4. [0.8] 'Illumina's iRefer program...' → 'Illumina's iRefer program...'\n",
      "     5. [0.8] 'MiSeq Operational Qualification...' → 'MiSeq Operational Qualification...'\n",
      "\n",
      "🎉 모든 CSV 내보내기 작업 완료!\n",
      "📂 파일 위치: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/3_processed/clean_tm_csv\n",
      "💡 Excel이나 텍스트 에디터로 파일을 열어서 정제 품질을 확인해보세요.\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# Cell 6: CSV 파일 내용 미리보기\n",
    "# ===================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"👀 생성된 CSV 파일 미리보기\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def preview_csv_file(filepath: str, rows: int = 5):\n",
    "    \"\"\"CSV 파일 미리보기\"\"\"\n",
    "    filename = os.path.basename(filepath)\n",
    "    print(f\"\\n📄 {filename}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(filepath)\n",
    "        print(f\"   📊 크기: {len(df):,}행 × {len(df.columns)}열\")\n",
    "        print(f\"   📋 컬럼: {', '.join(df.columns[:5])}{'...' if len(df.columns) > 5 else ''}\")\n",
    "        \n",
    "        print(f\"   🔍 처음 {rows}행:\")\n",
    "        for i, (_, row) in enumerate(df.head(rows).iterrows()):\n",
    "            source = str(row.get('source_text', ''))[:50]\n",
    "            target = str(row.get('target_text', ''))[:50]\n",
    "            quality = row.get('quality_score', 'N/A')\n",
    "            print(f\"     {i+1}. [{quality}] '{source}...' → '{target}...'\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ❌ 미리보기 오류: {str(e)}\")\n",
    "\n",
    "# 주요 파일들 미리보기\n",
    "preview_files = [f for f in exported_files if 'with_metadata' in f]  # 메타데이터 포함 파일만\n",
    "preview_files.extend(sample_files)  # 샘플 파일들\n",
    "\n",
    "for filepath in preview_files[:4]:  # 최대 4개 파일만 미리보기\n",
    "    preview_csv_file(filepath)\n",
    "\n",
    "print(f\"\\n🎉 모든 CSV 내보내기 작업 완료!\")\n",
    "print(f\"📂 파일 위치: {csv_output_dir}\")\n",
    "print(f\"💡 Excel이나 텍스트 에디터로 파일을 열어서 정제 품질을 확인해보세요.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mywork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
