{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d1f2231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 1: ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from processors._pdf_text_extractor import PDFTextExtractor\n",
    "from processors._pdf_pair_matcher import PDFPairMatcher\n",
    "from processors._translation_pair_generator import TranslationPairGenerator\n",
    "from config import PROCESSED_DIR\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29d6ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========================================\n",
    "# Cell 2: PDF í˜ì–´ ì°¾ê¸°\n",
    "# ========================================\n",
    "\n",
    "print(\"ğŸ” PDF í˜ì–´ë¥¼ ì°¾ëŠ” ì¤‘...\")\n",
    "\n",
    "matcher = PDFPairMatcher()\n",
    "pdf_pairs = matcher.find_pdf_pairs()\n",
    "\n",
    "if pdf_pairs:\n",
    "    print(f\"âœ… {len(pdf_pairs)}ê°œì˜ PDF í˜ì–´ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.\")\n",
    "    for en_path, ko_path in pdf_pairs[:3]:  # ì²˜ìŒ 3ê°œë§Œ í‘œì‹œ\n",
    "        print(f\"   - {os.path.basename(ko_path)}\")\n",
    "    if len(pdf_pairs) > 3:\n",
    "        print(f\"   ... ì™¸ {len(pdf_pairs)-3}ê°œ\")\n",
    "else:\n",
    "    print(\"âŒ ë§¤ì¹­ë˜ëŠ” PDF í˜ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9226bf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 3: í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë²ˆì—­ ìŒ ìƒì„±\n",
    "# ========================================\n",
    "\n",
    "if not pdf_pairs:\n",
    "    print(\"âŒ ì²˜ë¦¬í•  PDF í˜ì–´ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "else:\n",
    "    print(\"\\nğŸ“– í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë²ˆì—­ ìŒ ìƒì„±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    extractor = PDFTextExtractor(min_text_length=20)\n",
    "    generator = TranslationPairGenerator(similarity_threshold=0.7)\n",
    "    \n",
    "    all_pairs = []\n",
    "    \n",
    "    for i, (en_path, ko_path) in enumerate(pdf_pairs):\n",
    "        print(f\"\\n[{i+1}/{len(pdf_pairs)}] ì²˜ë¦¬ ì¤‘: {os.path.basename(ko_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # í…ìŠ¤íŠ¸ ì¶”ì¶œ\n",
    "            en_segments = extractor.extract_segments_from_pdf(en_path)\n",
    "            ko_segments = extractor.extract_segments_from_pdf(ko_path)\n",
    "            \n",
    "            print(f\"   - ì˜ì–´: {len(en_segments)}ê°œ, í•œêµ­ì–´: {len(ko_segments)}ê°œ ì„¸ê·¸ë¨¼íŠ¸\")\n",
    "            \n",
    "            # ë²ˆì—­ ìŒ ìƒì„±\n",
    "            pairs = generator.generate_pairs(en_segments, ko_segments, ko_path)\n",
    "            all_pairs.extend(pairs)\n",
    "            \n",
    "            print(f\"   - âœ… {len(pairs)}ê°œ ë²ˆì—­ ìŒ ìƒì„±\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   - âŒ ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "    print(f\"\\nğŸ‰ ì´ {len(all_pairs)}ê°œì˜ ë²ˆì—­ ìŒì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39800003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 4: ê²°ê³¼ ì €ì¥ ë° ë¯¸ë¦¬ë³´ê¸°\n",
    "# ========================================\n",
    "\n",
    "if all_pairs:\n",
    "    # ê²°ê³¼ ì €ì¥\n",
    "    csv_path = os.path.join(PROCESSED_DIR, \"pdf_translation_pairs.csv\")\n",
    "    \n",
    "    df = pd.DataFrame(all_pairs)\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {csv_path}\")\n",
    "    print(f\"ğŸ“Š í‰ê·  ìœ ì‚¬ë„: {df['similarity_score'].mean():.3f}\")\n",
    "    print(f\"ğŸ“„ ì†ŒìŠ¤ íŒŒì¼ ìˆ˜: {df['source_file'].nunique()}ê°œ\")\n",
    "    \n",
    "    # ë¯¸ë¦¬ë³´ê¸°\n",
    "    print(\"\\nğŸ” ìƒìœ„ 3ê°œ ë²ˆì—­ ìŒ ë¯¸ë¦¬ë³´ê¸°:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    top_pairs = df.nlargest(3, 'similarity_score')\n",
    "    \n",
    "    for i, (_, row) in enumerate(top_pairs.iterrows(), 1):\n",
    "        print(f\"\\n[{i}] ìœ ì‚¬ë„: {row['similarity_score']:.3f}\")\n",
    "        print(f\"ğŸ‡ºğŸ‡¸ {row['source_text'][:80]}{'...' if len(row['source_text']) > 80 else ''}\")\n",
    "        print(f\"ğŸ‡°ğŸ‡· {row['target_text'][:80]}{'...' if len(row['target_text']) > 80 else ''}\")\n",
    "        \n",
    "else:\n",
    "    print(\"âš ï¸ ì €ì¥í•  ë²ˆì—­ ìŒì´ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mywork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
