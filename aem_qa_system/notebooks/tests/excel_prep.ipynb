{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "076284e8",
   "metadata": {},
   "source": [
    "# Excel íŒŒì¼ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ Excel íŒŒì¼ì„ ì½ì–´ CSVë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì„¤ì • ì‚¬í•­\n",
    "- í”„ë¡œì íŠ¸ ë£¨íŠ¸: `/home/cjkim/illumina/aem_qa_system`\n",
    "- ëŒ€ìƒ íŒŒì¼ ê²½ë¡œ: `data/1_input/source_excels/glossary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bee439c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# src/utils/excel_processor.py\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from src.config import PROJECT_ROOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8182178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing.util import is_exiting\n",
    "\n",
    "\n",
    "for root, dirs, files in os.walk(PROJECT_ROOT):\n",
    "    for file in files:\n",
    "        if file.endswith(\"xlsx\"):\n",
    "            print(os.path.join(root,file))\n",
    "        elif dirs:\n",
    "            for _ in dirs:\n",
    "                print(f\"{root}/{_}/\")\n",
    "        else:\n",
    "            print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "94a9d7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_and_tag_excels_from_folder(folder_path: str) -> pd.DataFrame | None:\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  Excelì„ ì½ê³ , 'Source_File' ì»¬ëŸ¼ì„ ì¶”ê°€í•œ í›„,\n",
    "    í•˜ë‚˜ì˜ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ í•©ì³ì„œ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    excel_files = glob.glob(os.path.join(folder_path, \"*.xlsx\"))\n",
    "    if not excel_files:\n",
    "        print(f\"âš ï¸ ê²½ê³ : '{folder_path}' í´ë”ì— Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "        return None\n",
    "\n",
    "    all_dfs = []\n",
    "    for file_path in excel_files:\n",
    "        df = pd.read_excel(file_path)\n",
    "        df['Source_File'] = os.path.basename(file_path)\n",
    "        all_dfs.append(df)\n",
    "    \n",
    "    return pd.concat(all_dfs, ignore_index=True)\n",
    "# â–²â–²â–²â–²â–² [ì‹ ê·œ] ì¤‘ë³µ ë¡œì§ì„ ì²˜ë¦¬í•˜ëŠ” ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜ â–²â–²â–²â–²â–²"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f57471",
   "metadata": {},
   "outputs": [],
   "source": [
    "glossary_path = os.path.join(PROJECT_ROOT, \"data/1_input/source_excels/glossary\")\n",
    "df = _load_and_tag_excels_from_folder(glossary_path)\n",
    "df[['en-US', 'ko-KR', 'Source_File']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38da9348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ë©´ ë‚´ìš© í™•ì¸\n",
    "def check_dir_content(dir_path, name):\n",
    "    if os.path.exists(dir_path):\n",
    "        print(f\"\\n{name} ë””ë ‰í† ë¦¬ ë‚´ìš©:\")\n",
    "        entries = os.listdir(dir_path)\n",
    "        \n",
    "        print(f\"ì´ {len(entries)}ê°œ í•­ëª© ë°œê²¬\")\n",
    "        \n",
    "        # íŒŒì¼ê³¼ ë””ë ‰í† ë¦¬ ë¶„ë¥˜\n",
    "        files = []\n",
    "        dirs = []\n",
    "        \n",
    "        for entry in entries:\n",
    "            full_path = os.path.join(dir_path, entry)\n",
    "            if os.path.isdir(full_path):\n",
    "                dirs.append(entry)\n",
    "            else:\n",
    "                files.append(entry)\n",
    "        \n",
    "        # ë””ë ‰í† ë¦¬ ëª©ë¡ ì¶œë ¥\n",
    "        if dirs:\n",
    "            print(f\"\\në””ë ‰í† ë¦¬ ({len(dirs)}ê°œ):\")\n",
    "            for directory in dirs:\n",
    "                dir_path_full = os.path.join(dir_path, directory)\n",
    "                dir_contents = os.listdir(dir_path_full)\n",
    "                print(f\" - ğŸ“ {directory} ({len(dir_contents)}ê°œ í•­ëª©)\")\n",
    "        \n",
    "        # íŒŒì¼ ëª©ë¡ ì¶œë ¥\n",
    "        if files:\n",
    "            print(f\"\\níŒŒì¼ ({len(files)}ê°œ):\")\n",
    "            for file in files:\n",
    "                ext = os.path.splitext(file)[1]\n",
    "                if ext in ['.xlsx', '.xls']:\n",
    "                    print(f\" - ğŸ“Š {file}\")\n",
    "                else:\n",
    "                    print(f\" - ğŸ“„ {file}\")\n",
    "        \n",
    "        # Excel íŒŒì¼ë§Œ í•„í„°ë§\n",
    "        excel_files = [f for f in files if f.endswith(('.xlsx', '.xls'))]\n",
    "        if excel_files:\n",
    "            print(f\"\\n{name}ì—ì„œ ë°œê²¬ëœ Excel íŒŒì¼: {excel_files}\")\n",
    "    else:\n",
    "        print(f\"\\n{name} ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì–‘ìª½ ê²½ë¡œ ëª¨ë‘ í™•ì¸\n",
    "check_dir_content(PROJECT_ROOT, \"í”„ë¡œì íŠ¸ ë‚´ ê²½ë¡œ\")\n",
    "# check_dir_content(home_glossary_path, \"í™ˆ ê¸°ì¤€ ê²½ë¡œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6a27ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_glossary_excel_to_csv(input_folder_path: str,\n",
    "                                  output_csv_path: str,\n",
    "                                  source_col: str,\n",
    "                                  target_col: str):\n",
    "    \"\"\"\n",
    "    [ë‹¨ìˆœ ë³€í™˜ìš©] ìš©ì–´ì§‘ í´ë”ì˜ Excel íŒŒì¼ë“¤ì„ ì½ì–´ í•˜ë‚˜ì˜ CSVë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    # ... (ì´ì „ ì œì•ˆê³¼ ë™ì¼í•œ ê°„ë‹¨í•œ ì²˜ë¦¬ ë¡œì§)\n",
    "    print(f\"ğŸ”„ ìš©ì–´ì§‘ í´ë” ì²˜ë¦¬ ì¤‘: '{os.path.basename(input_folder_path)}'...\")\n",
    "    try:\n",
    "        excel_files = glob.glob(os.path.join(input_folder_path, \"*.xlsx\"))\n",
    "        if not excel_files:\n",
    "            print(f\"âš ï¸ ê²½ê³ : '{input_folder_path}' í´ë”ì— Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return False\n",
    "    \n",
    "        \n",
    "        df = pd.concat([pd.read_excel(f) for f in excel_files], ignore_index=True) # dfì— ë§ê²Œ ìƒˆë¡œì´ indexìƒì„±\n",
    "        df_processed = df[[source_col, target_col]].copy()\n",
    "        df_processed.rename(columns={source_col: 'Source', target_col: 'Target'}, inplace=True) # inplaceë¥¼ ì‚¬ìš©í•´ì„œ ì›ë³¸dfë¥¼ ì§ì ‘ ìˆ˜ì •\n",
    "        df_processed.dropna(subset=['Source', 'Target'], inplace=True)\n",
    "        df_processed.drop_duplicates(subset=['Source', 'Target'], inplace=True)\n",
    "        \n",
    "        os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "        df_processed.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"âœ… ì™„ë£Œ: '{os.path.basename(output_csv_path)}' ìƒì„± ({len(df_processed)}ê°œ í–‰)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56db0477",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ê²½ë¡œ ì„¤ì •í•˜ê¸°\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì„¤ì •\n",
    "project_root = \"/home/cjkim/illumina/aem_qa_system\"\n",
    "print(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")\n",
    "\n",
    "# 2. ìƒëŒ€ ê²½ë¡œ ì„¤ì •\n",
    "rel_path = \"data/1_input/source_excels/glossary\"\n",
    "full_path = os.path.join(project_root, rel_path)\n",
    "print(f\"ìƒëŒ€ ê²½ë¡œ: {rel_path}\")\n",
    "print(f\"ì „ì²´ ê²½ë¡œ: {full_path}\")\n",
    "\n",
    "# 3. íŒŒì¼ ì°¾ê¸°\n",
    "excel_files = glob.glob(os.path.join(full_path, \"*.xlsx\"))\n",
    "print(f\"ì°¾ì€ Excel íŒŒì¼ ìˆ˜: {len(excel_files)}\")\n",
    "\n",
    "if excel_files:\n",
    "    print(\"\\níŒŒì¼ ëª©ë¡:\")\n",
    "    for file in excel_files:\n",
    "        # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ í‘œì‹œ\n",
    "        rel_file_path = os.path.relpath(file, project_root)\n",
    "        print(f\" - {rel_file_path}\")\n",
    "        \n",
    "    # ì²« ë²ˆì§¸ íŒŒì¼ì„ ì‚¬ìš©í•˜ì—¬ process_excel_folder_to_csv í•¨ìˆ˜ ì‹¤í–‰ ì˜ˆì‹œ\n",
    "    print(\"\\ní”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ ìƒëŒ€ ê²½ë¡œë¡œ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ê²½ìš°:\")\n",
    "    print(f\"input_folder_path='{rel_path}'\")\n",
    "    print(f\"output_csv_path='{os.path.join(rel_path, 'processed_output.csv')}'\")\n",
    "else:\n",
    "    print(\"Excel íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fbea48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_excel_folder_to_csv(input_folder_path: str,\n",
    "                                output_csv_path: str,\n",
    "                                source_col: str,\n",
    "                                target_col: str):\n",
    "    \"\"\"\n",
    "    ì§€ì •ëœ í´ë” ì•ˆì˜ ëª¨ë“  Excel íŒŒì¼ì„ ì½ì–´ 'Source_File' ì¶œì²˜ë¥¼ í¬í•¨í•œ CSVë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "    \n",
    "    Args:\n",
    "        input_folder_path: Excel íŒŒì¼ì´ ìˆëŠ” í´ë” ê²½ë¡œ\n",
    "        output_csv_path: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ\n",
    "        source_col: ì›ë³¸ ì–¸ì–´ ì»¬ëŸ¼ëª…\n",
    "        target_col: ëŒ€ìƒ ì–¸ì–´ ì»¬ëŸ¼ëª…\n",
    "        \n",
    "    Returns:\n",
    "        bool: ì„±ê³µ ì‹œ True, ì‹¤íŒ¨ ì‹œ False\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ í´ë” ì²˜ë¦¬ ì¤‘: '{os.path.basename(input_folder_path)}'...\")\n",
    "    try:\n",
    "        # 1. Excel íŒŒì¼ ì°¾ê¸°\n",
    "        excel_files = glob.glob(os.path.join(input_folder_path, \"*.xlsx\"))\n",
    "        if not excel_files:\n",
    "            print(f\"âš ï¸ ê²½ê³ : '{input_folder_path}' í´ë”ì— Excel íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return False\n",
    "        \n",
    "        print(f\"ğŸ“Š ì²˜ë¦¬í•  Excel íŒŒì¼ ìˆ˜: {len(excel_files)}\")\n",
    "        \n",
    "        # 2. ê° Excel íŒŒì¼ ì²˜ë¦¬\n",
    "        all_dfs = []\n",
    "        for file_path in excel_files:\n",
    "            print(f\"ğŸ“„ íŒŒì¼ ì²˜ë¦¬ ì¤‘: {os.path.basename(file_path)}\")\n",
    "            df = pd.read_excel(file_path)\n",
    "            \n",
    "            # ì›ë³¸ íŒŒì¼ëª… ì¶”ê°€\n",
    "            df['Source_File'] = os.path.basename(file_path)\n",
    "            all_dfs.append(df)\n",
    "        \n",
    "        # 3. ëª¨ë“  ë°ì´í„°í”„ë ˆì„ í•©ì¹˜ê¸°\n",
    "        combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "        print(f\"ğŸ‘‰ ëª¨ë“  íŒŒì¼ ë³‘í•© ì™„ë£Œ: ì´ {len(combined_df)}ê°œ í–‰\")\n",
    "        \n",
    "        # 4. ì»¬ëŸ¼ ì„ íƒ ë° ì´ë¦„ ë³€ê²½\n",
    "        df_processed = combined_df[[source_col, target_col, 'Source_File']].copy()\n",
    "        df_processed.rename(columns={source_col: 'Source', target_col: 'Target'}, inplace=True)\n",
    "        \n",
    "        # 5. ë°ì´í„° ì •ì œ\n",
    "        # - NA ê°’ ì œê±°\n",
    "        before_na_drop = len(df_processed)\n",
    "        df_processed.dropna(subset=['Source', 'Target'], inplace=True)\n",
    "        after_na_drop = len(df_processed)\n",
    "        print(f\"ğŸ§¹ NA ê°’ ì œê±°: {before_na_drop - after_na_drop}ê°œ í–‰ ì œê±°ë¨\")\n",
    "        \n",
    "        # - ì¤‘ë³µ ì œê±°\n",
    "        before_dedup = len(df_processed)\n",
    "        df_processed.drop_duplicates(subset=['Source', 'Target'], inplace=True)\n",
    "        after_dedup = len(df_processed)\n",
    "        print(f\"ğŸ§¹ ì¤‘ë³µ ì œê±°: {before_dedup - after_dedup}ê°œ í–‰ ì œê±°ë¨\")\n",
    "        \n",
    "        # 6. CSVë¡œ ì €ì¥\n",
    "        # - ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "        os.makedirs(os.path.dirname(output_csv_path), exist_ok=True)\n",
    "        \n",
    "        # - CSV ì €ì¥\n",
    "        df_processed.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(f\"âœ… ì™„ë£Œ: '{os.path.basename(output_csv_path)}' ìƒì„± ({len(df_processed)}ê°œ í–‰)\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc078778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ process_excel_folder_to_csv í•¨ìˆ˜ ì‹¤í–‰\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# 1. í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì • ë° ì´ë¥¼ sys.pathì— ì¶”ê°€\n",
    "project_root = \"/home/cjkim/illumina/aem_qa_system\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)  # í”„ë¡œì íŠ¸ ëª¨ë“ˆ importë¥¼ ìœ„í•´ í•„ìš”í•  ê²½ìš°\n",
    "\n",
    "# 2. ìƒëŒ€ ê²½ë¡œ ì„¤ì •\n",
    "input_rel_path = \"data/1_input/source_excels/glossary\"\n",
    "output_rel_path = \"data/1_input/source_excels/glossary/test.csv\"\n",
    "\n",
    "# 3. ì „ì²´ ê²½ë¡œë¡œ ë³€í™˜ (í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ í•„ìš”í•œ ê²½ìš°)\n",
    "input_full_path = os.path.join(project_root, input_rel_path)\n",
    "output_full_path = os.path.join(project_root, output_rel_path)\n",
    "\n",
    "print(f\"í”„ë¡œì íŠ¸ ë£¨íŠ¸: {project_root}\")\n",
    "print(f\"ì…ë ¥ ìƒëŒ€ ê²½ë¡œ: {input_rel_path}\")\n",
    "print(f\"ì¶œë ¥ ìƒëŒ€ ê²½ë¡œ: {output_rel_path}\")\n",
    "\n",
    "# 4. ë””ë ‰í† ë¦¬ ì¡´ì¬ í™•ì¸\n",
    "if os.path.exists(input_full_path):\n",
    "    print(f\"\\nâœ… ì…ë ¥ ê²½ë¡œê°€ ì¡´ì¬í•©ë‹ˆë‹¤: {input_rel_path}\")\n",
    "    \n",
    "    # 5. ë””ë ‰í† ë¦¬ ë‚´ìš© ì¶œë ¥ (íŒŒì¼ ì´ë¦„ë§Œ)\n",
    "    files = os.listdir(input_full_path)\n",
    "    excel_files = [f for f in files if f.endswith('.xlsx')]\n",
    "    \n",
    "    print(f\"Excel íŒŒì¼ ìˆ˜: {len(excel_files)}\")\n",
    "    if excel_files:\n",
    "        print(f\"Excel íŒŒì¼ ëª©ë¡:\")\n",
    "        for excel_file in excel_files:\n",
    "            print(f\" - {excel_file}\")\n",
    "    \n",
    "    # 6. í•¨ìˆ˜ ì‹¤í–‰\n",
    "    result = process_excel_folder_to_csv(\n",
    "        input_folder_path=input_full_path,  # ì „ì²´ ê²½ë¡œ ì‚¬ìš©\n",
    "        output_csv_path=output_full_path,   # ì „ì²´ ê²½ë¡œ ì‚¬ìš©\n",
    "        source_col=\"en-US\",\n",
    "        target_col=\"ko-KR\"\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nì‹¤í–‰ ê²°ê³¼: {'ì„±ê³µ âœ…' if result else 'ì‹¤íŒ¨ âŒ'}\")\n",
    "else:\n",
    "    print(f\"âŒ ì…ë ¥ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {input_rel_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7637037d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_tm_excel_to_csv(input_folder_path: str,\n",
    "                            output_csv_path: str,\n",
    "                            source_col: str,\n",
    "                            # ... (ì´í•˜ íŒŒë¼ë¯¸í„° ë™ì¼)\n",
    "                            ):\n",
    "    \"\"\"\n",
    "    [ì¡°ê±´ë¶€ ì—…ë°ì´íŠ¸ìš©] TM í´ë”ì˜ Excel íŒŒì¼ë“¤ì„ ì½ì–´,\n",
    "    'Source_File' ì¶œì²˜ë¥¼ í¬í•¨í•˜ì—¬ í•˜ë‚˜ì˜ CSVë¡œ í†µí•©í•©ë‹ˆë‹¤.\n",
    "    \"\"\"\n",
    "    print(f\"ğŸ”„ TM í´ë” ì²˜ë¦¬ ì¤‘ (ì—…ë°ì´íŠ¸ ë¡œì§ ì ìš©): '{os.path.basename(input_folder_path)}'...\")\n",
    "    try:\n",
    "        # ... (Excel íŒŒì¼ ì½ê¸° ë° 'Source_File' ì»¬ëŸ¼ ì¶”ê°€ ë¡œì§ì€ ìœ„ì™€ ë™ì¼)\n",
    "        \n",
    "        all_dfs = []\n",
    "        for file_path in glob.glob(os.path.join(input_folder_path, \"*.xlsx\")):\n",
    "            df = pd.read_excel(file_path)\n",
    "            df['Source_File'] = os.path.basename(file_path)\n",
    "            all_dfs.append(df)\n",
    "        \n",
    "        df = pd.concat(all_dfs, ignore_index=True)\n",
    "\n",
    "        # 1. ìµœì¢… Target ê²°ì • ë¡œì§\n",
    "        df['Final_Target'] = np.where(...)\n",
    "\n",
    "        # 2. ì›ë³¸(en-US)ê³¼ ìµœì¢… Target ìŒ ìƒì„±\n",
    "        df1 = df[[source_col, 'Final_Target', 'Source_File']].copy()\n",
    "        df1.rename(columns={source_col: 'Source', 'Final_Target': 'Target'}, inplace=True)\n",
    "        \n",
    "        # 3. ì—…ë°ì´íŠ¸(en-US1)ì™€ ìµœì¢… Target ìŒ ìƒì„±\n",
    "        df2 = df[df[source_col_updated].notna()][[source_col_updated, 'Final_Target', 'Source_File']].copy()\n",
    "        df2.rename(columns={source_col_updated: 'Source', 'Final_Target': 'Target'}, inplace=True)\n",
    "\n",
    "        # 4. ë‘ ìŒì˜ ëª©ë¡ì„ í•˜ë‚˜ë¡œ í•©ì¹˜ê³  ì •ì œ\n",
    "        final_df = pd.concat([df1, df2], ignore_index=True)\n",
    "        final_df.dropna(subset=['Source', 'Target'], inplace=True)\n",
    "        # ì´ì œ Source, Target, Source_File ì„¸ ê°€ì§€ê°€ ëª¨ë‘ ê°™ì•„ì•¼ ì¤‘ë³µìœ¼ë¡œ ê°„ì£¼\n",
    "        final_df.drop_duplicates(subset=['Source', 'Target', 'Source_File'], inplace=True)\n",
    "        \n",
    "        # 5. CSVë¡œ ì €ì¥\n",
    "        final_df.to_csv(output_csv_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "        print(f\"âœ… ì™„ë£Œ: '{os.path.basename(output_csv_path)}' ìƒì„± ({len(final_df)}ê°œ í–‰)\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        # ...\n",
    "        return False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mywork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
