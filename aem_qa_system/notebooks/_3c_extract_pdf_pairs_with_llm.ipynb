{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7dc5e947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 LLM 기반 PDF 번역쌍 추출 시작\n",
      "🌐 처리할 언어 쌍: [('en', 'ko'), ('en', 'ja')]\n",
      "📁 PDF 폴더: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/2_downloaded/pdfs\n",
      "📁 결과 저장 폴더: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/3_processed\n",
      "   - EN: 101개 PDF\n",
      "   - KO: ❌ 폴더 없음 (/mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/2_downloaded/pdfs/ko)\n",
      "   - EN: 101개 PDF\n",
      "   - JA: 95개 PDF\n"
     ]
    }
   ],
   "source": [
    "# notebooks/3c_extract_pdf_pairs_with_llm.ipynb\n",
    "\n",
    "# ========================================\n",
    "# Cell 1: 라이브러리 import 및 설정\n",
    "# ========================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "sys.path.append(os.path.abspath('../src'))\n",
    "\n",
    "from processors.pdf_text_extractor import PDFTextExtractor\n",
    "from processors.pdf_pair_matcher import PDFPairMatcher\n",
    "from processors.llm_pdf_tm_generator import LLMPDFTMGenerator  # 🆕 새로운 LLM 생성기\n",
    "from config import PROCESSED_DIR, PDF_DOWNLOAD_DIR\n",
    "\n",
    "# 처리할 언어 쌍들 정의\n",
    "LANGUAGE_PAIRS = [\n",
    "    ('en', 'ko'),  # 영어-한국어\n",
    "    ('en', 'ja'),  # 영어-일본어\n",
    "]\n",
    "\n",
    "# 필요한 디렉토리 생성\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"🤖 LLM 기반 PDF 번역쌍 추출 시작\")\n",
    "print(f\"🌐 처리할 언어 쌍: {LANGUAGE_PAIRS}\")\n",
    "print(f\"📁 PDF 폴더: {PDF_DOWNLOAD_DIR}\")\n",
    "print(f\"📁 결과 저장 폴더: {PROCESSED_DIR}\")\n",
    "\n",
    "# PDF 폴더 존재 확인\n",
    "for lang_pair in LANGUAGE_PAIRS:\n",
    "    for lang in lang_pair:\n",
    "        lang_dir = os.path.join(PDF_DOWNLOAD_DIR, lang)\n",
    "        if os.path.exists(lang_dir):\n",
    "            pdf_count = len([f for f in os.listdir(lang_dir) if f.endswith('.pdf')])\n",
    "            print(f\"   - {lang.upper()}: {pdf_count}개 PDF\")\n",
    "        else:\n",
    "            print(f\"   - {lang.upper()}: ❌ 폴더 없음 ({lang_dir})\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c667095d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "🔄 EN-KO 언어 쌍 처리 시작 (LLM 기반)\n",
      "================================================================================\n",
      "❌ 매칭 테이블을 찾을 수 없습니다: /mnt/d/Cloud-Synced/Illumina/OneDrive - Illumina, Inc/aem_qa_system/data/1_input/pdf_list_master_en_ko.csv\n",
      "❌ EN-KO PDF 페어를 찾을 수 없습니다.\n",
      "\n",
      "================================================================================\n",
      "🔄 EN-JA 언어 쌍 처리 시작 (LLM 기반)\n",
      "================================================================================\n",
      "📋 EN-JA 매칭 테이블에서 101개 항목을 로드했습니다.\n",
      "✅ 실제 존재하는 100개의 EN-JA PDF 페어를 발견했습니다.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_pairs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     25\u001b[39m pairs_for_this_language = []\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# 🔧 일부만 처리하여 테스트 (전체 처리는 시간이 오래 걸림)\u001b[39;00m\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# test_pairs = pdf_pairs[:]  # 처음 5개만 테스트\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (source_path, target_path) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[43mtest_pairs\u001b[49m):\n\u001b[32m     31\u001b[39m     \u001b[38;5;66;03m# print(f\"\\n[{i+1}/{len(test_pairs)}] 📄 처리 중: {os.path.basename(target_path)}\")\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     34\u001b[39m         \u001b[38;5;66;03m# 🆕 기본 텍스트 추출 (수정된 방식)\u001b[39;00m\n\u001b[32m     35\u001b[39m         \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfitz\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'test_pairs' is not defined"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# Cell 2: LLM 기반 처리 (개선된 버전)\n",
    "# ========================================\n",
    "\n",
    "# 🆕 LLM 기반 생성기 초기화\n",
    "llm_generator = LLMPDFTMGenerator(fast_mode=True)\n",
    "basic_extractor = PDFTextExtractor(min_text_length=25)\n",
    "\n",
    "all_results = {}\n",
    "\n",
    "for source_lang, target_lang in LANGUAGE_PAIRS:\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"🔄 {source_lang.upper()}-{target_lang.upper()} 언어 쌍 처리 시작 (LLM 기반)\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # 1. PDF 페어 찾기\n",
    "    matcher = PDFPairMatcher(source_lang, target_lang)\n",
    "    pdf_pairs = matcher.find_pdf_pairs()\n",
    "    \n",
    "    if not pdf_pairs:\n",
    "        print(f\"❌ {source_lang.upper()}-{target_lang.upper()} PDF 페어를 찾을 수 없습니다.\")\n",
    "        continue\n",
    "    \n",
    "    # 2. LLM 기반 번역 쌍 생성\n",
    "    pairs_for_this_language = []\n",
    "    \n",
    "    # 🔧 일부만 처리하여 테스트 (전체 처리는 시간이 오래 걸림)\n",
    "    test_pairs = pdf_pairs[:]  # 처음 5개만 테스트\n",
    "    \n",
    "    for i, (source_path, target_path) in enumerate(test_pairs):\n",
    "        print(f\"\\n[{i+1}/{len(test_pairs)}] 📄 처리 중: {os.path.basename(target_path)}\")\n",
    "        \n",
    "        try:\n",
    "            # 🆕 기본 텍스트 추출 (수정된 방식)\n",
    "            import fitz\n",
    "            \n",
    "            # Source PDF 텍스트 추출\n",
    "            source_raw_text = \"\"\n",
    "            with fitz.open(source_path) as doc:\n",
    "                for page in doc:\n",
    "                    source_raw_text += page.get_text() + \"\\n\\n\"\n",
    "            \n",
    "            # Target PDF 텍스트 추출  \n",
    "            target_raw_text = \"\"\n",
    "            with fitz.open(target_path) as doc:\n",
    "                for page in doc:\n",
    "                    target_raw_text += page.get_text() + \"\\n\\n\"\n",
    "            \n",
    "            print(f\"   - 원본 텍스트 추출 완료 ({len(source_raw_text)} / {len(target_raw_text)} 문자)\")\n",
    "            \n",
    "            # 🆕 LLM으로 의미있는 세그먼트 생성\n",
    "            print(f\"   - 🤖 {source_lang.upper()} LLM 세그먼트 생성 중...\")\n",
    "            source_segments = llm_generator.generate_meaningful_segments(source_raw_text, source_lang, target_lang)\n",
    "            \n",
    "            print(f\"   - 🤖 {target_lang.upper()} LLM 세그먼트 생성 중...\")\n",
    "            target_segments = llm_generator.generate_meaningful_segments(target_raw_text, target_lang, source_lang)\n",
    "            \n",
    "            print(f\"   - LLM 세그먼트: {source_lang.upper()} {len(source_segments)}개, {target_lang.upper()} {len(target_segments)}개\")\n",
    "\n",
    "            # 함수 호출 전에 디버깅 출력 추가\n",
    "            print(f\"   - 함수 호출 인자: source_segments({len(source_segments)}), target_segments({len(target_segments)})\")\n",
    "            print(f\"   - 경로: {source_path}, {target_path}\")\n",
    "            print(f\"   - 언어: {source_lang}, {target_lang}\")\n",
    "\n",
    "            \n",
    "            # 🆕 문맥 정보를 포함한 번역 쌍 생성\n",
    "            pairs = llm_generator.create_translation_pairs_with_context(\n",
    "                source_segments, target_segments, \n",
    "                source_path, target_path,  # 🆕 source_path 추가\n",
    "                source_lang, target_lang\n",
    "            )\n",
    "            pairs_for_this_language.extend(pairs)\n",
    "            \n",
    "            print(f\"   - ✅ {len(pairs)}개 고품질 번역 쌍 생성\")\n",
    "            \n",
    "            # 샘플 결과 출력\n",
    "            if pairs:\n",
    "                sample = pairs[0]\n",
    "                print(f\"   - 🔍 샘플 (유사도: {sample['similarity_score']:.3f}):\")\n",
    "                print(f\"     {source_lang.upper()}: {sample['source_text'][:60]}...\")\n",
    "                print(f\"     {target_lang.upper()}: {sample['target_text'][:60]}...\")\n",
    "                print(f\"     카테고리: {sample.get('source_category', 'N/A')} → {sample.get('target_category', 'N/A')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   - ❌ 오류: {e}\")\n",
    "    \n",
    "    all_results[f\"{source_lang}_{target_lang}\"] = pairs_for_this_language\n",
    "    print(f\"\\n🎉 {source_lang.upper()}-{target_lang.upper()}: 총 {len(pairs_for_this_language)}개 고품질 번역 쌍 완료!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "397d9194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 3: 결과 비교 및 저장\n",
    "# ========================================\n",
    "\n",
    "total_pairs = 0\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"📊 LLM 기반 번역쌍 추출 결과\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for lang_pair, pairs in all_results.items():\n",
    "    if pairs:\n",
    "        # 🆕 향상된 결과 파일 저장\n",
    "        csv_path = os.path.join(PROCESSED_DIR, f\"pdf_translation_pairs_{lang_pair}_llm_enhanced.csv\")\n",
    "        df = pd.DataFrame(pairs)\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        total_pairs += len(pairs)\n",
    "        source_lang, target_lang = lang_pair.split('_')\n",
    "        \n",
    "        print(f\"\\n🌐 {source_lang.upper()}-{target_lang.upper()}:\")\n",
    "        print(f\"   💾 저장: {os.path.basename(csv_path)}\")\n",
    "        print(f\"   📄 번역 쌍: {len(pairs)}개\")\n",
    "        print(f\"   📊 평균 유사도: {df['similarity_score'].mean():.3f}\")\n",
    "        print(f\"   🎯 평균 신뢰도: {df['source_confidence'].mean():.3f}\")\n",
    "        \n",
    "        # 🆕 카테고리별 분포\n",
    "        if 'source_category' in df.columns:\n",
    "            category_dist = df['source_category'].value_counts()\n",
    "            print(f\"   📋 카테고리 분포: {dict(category_dist)}\")\n",
    "\n",
    "# 🆕 품질 향상 분석\n",
    "if total_pairs > 0:\n",
    "    print(f\"\\n🎉 LLM 기반 고품질 번역쌍 추출 완료!\")\n",
    "    print(f\"   📈 총 번역 쌍: {total_pairs}개\")\n",
    "    print(f\"   🚀 기존 대비 예상 품질 향상: 높은 문맥 보존, 의미 단위 완성도\")\n",
    "    print(f\"   💡 다음 단계: 이 데이터를 base_tm.csv와 통합하여 최종 TM 구축\")\n",
    "else:\n",
    "    print(f\"\\n⚠️ 생성된 번역 쌍이 없습니다. 설정을 확인해주세요.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16ec689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# Cell 4: 결과 저장 및 분석\n",
    "# ========================================\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "total_pairs = 0\n",
    "all_pairs_combined = []\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"📊 LLM 기반 번역쌍 추출 결과 저장\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "for lang_pair, pairs in all_results.items():\n",
    "    if pairs:\n",
    "        source_lang, target_lang = lang_pair.split('_')\n",
    "        \n",
    "        # CSV 저장\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        csv_filename = f\"pdf_tm_{lang_pair}_llm_enhanced_{timestamp}.csv\"\n",
    "        csv_path = os.path.join(PROCESSED_DIR, csv_filename)\n",
    "        \n",
    "        df = pd.DataFrame(pairs)\n",
    "        df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        total_pairs += len(pairs)\n",
    "        all_pairs_combined.extend(pairs)\n",
    "        \n",
    "        print(f\"\\n🌐 {source_lang.upper()}-{target_lang.upper()}:\")\n",
    "        print(f\"   💾 저장: {csv_filename}\")\n",
    "        print(f\"   📄 번역 쌍: {len(pairs)}개\")\n",
    "        print(f\"   📊 평균 유사도: {df['similarity_score'].mean():.3f}\")\n",
    "\n",
    "# 통합 파일 저장\n",
    "# if total_pairs > 0:\n",
    "    # combined_timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    # combined_filename = f\"pdf_tm_all_languages_llm_enhanced_{combined_timestamp}.csv\"\n",
    "    # combined_csv_path = os.path.join(PROCESSED_DIR, combined_filename)\n",
    "    \n",
    "    # combined_df = pd.DataFrame(all_pairs_combined)\n",
    "    # combined_df.to_csv(combined_csv_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    # print(f\"\\n📦 통합 파일: {combined_filename}\")\n",
    "    # print(f\"   📊 전체 번역 쌍: {len(all_pairs_combined)}개\")\n",
    "    # print(f\"   🌐 지원 언어: {combined_df['target_lang'].unique().tolist()}\")\n",
    "\n",
    "print(f\"\\n✨ CSV 저장 완료!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mywork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
