# aem_qa_station/modules/searcher.py

import streamlit as st
from typing import List, Dict, Optional
from sentence_transformers import SentenceTransformer
import torch
from .connections import get_chroma_client

class TranslationSearcher:
    """ChromaDBë¥¼ ì‚¬ìš©í•œ AI ë²ˆì—­ ì¶”ì²œ í´ë˜ìŠ¤"""
    
    def __init__(self, lang_pair: str = "en_ko"):
        self.lang_pair = lang_pair
        self.chroma_client = get_chroma_client()
        self.collection = self._get_collection()
        self.embedding_model = self._load_embedding_model()
    
    @st.cache_resource
    def _load_embedding_model(_self):
        """ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. (Streamlit ìºì‹œ ì ìš©)"""
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
        model = SentenceTransformer('intfloat/multilingual-e5-large', device=device)
        print(f"âœ… ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì™„ë£Œ ({device})")
        return model
    
    def _get_collection(self):
        """ChromaDB ì»¬ë ‰ì…˜ì„ ê°€ì ¸ì˜µë‹ˆë‹¤."""
        try:
            collection_name = f"tm_{self.lang_pair}"
            collection = self.chroma_client.get_collection(name=collection_name)
            print(f"âœ… ChromaDB ì»¬ë ‰ì…˜ '{collection_name}' ì—°ê²° ì™„ë£Œ")
            return collection
        except Exception as e:
            print(f"âŒ ChromaDB ì»¬ë ‰ì…˜ ì—°ê²° ì‹¤íŒ¨: {e}")
            return None
    
    def search_similar_translations(self, query_text: str, 
                                  top_k: int = 3,
                                  exclude_exact_match: bool = True) -> List[Dict]:
        """ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ ë²ˆì—­ ì‚¬ë¡€ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤."""
        if not self.collection or not query_text.strip():
            return []
        
        try:
            # 1. ê²€ìƒ‰ì–´ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
            query_embedding = self.embedding_model.encode(
                query_text, 
                convert_to_tensor=True
            ).tolist()
            
            # 2. ChromaDBì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œ ê²€ìƒ‰ (ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§)
            search_limit = min(top_k * 3, 15)  # 3ë°° ë” ê°€ì ¸ì˜¤ê¸°
            results = self.collection.query(
                query_embeddings=[query_embedding],
                n_results=search_limit
            )
            
            # 3. ê²°ê³¼ ì •ë¦¬ ë° í•„í„°ë§
            recommendations = []
            query_text_clean = query_text.strip().lower()
            
            for i in range(len(results['ids'][0])):
                source_text = results['documents'][0][i]
                similarity_score = 1 - results['distances'][0][i]
                
                # ìê¸° ìì‹  ì œì™¸ (ì •í™•íˆ ë™ì¼í•œ í…ìŠ¤íŠ¸)
                if exclude_exact_match and source_text.strip().lower() == query_text_clean:
                    continue
                
                # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ì œì™¸
                if similarity_score < 0.3:
                    continue
                    
                # 100% ìœ ì‚¬ë„ë„ ì œì™¸ (ê±°ì˜ ë™ì¼í•œ í…ìŠ¤íŠ¸)
                if similarity_score >= 0.99:
                    continue
                
                metadata = results['metadatas'][0][i]
                recommendations.append({
                    'source_text': source_text,
                    'target_text': metadata.get('target_text', 'N/A'),
                    'similarity_score': round(similarity_score, 3),
                    'page_path': metadata.get('page_path', ''),
                    'component_path': metadata.get('component_path', ''),
                    'confidence_level': self._get_confidence_level(similarity_score)
                })
                
                # ì›í•˜ëŠ” ê°œìˆ˜ë§Œí¼ ì°¾ì•˜ìœ¼ë©´ ì¤‘ë‹¨
                if len(recommendations) >= top_k:
                    break
            
            return recommendations
            
        except Exception as e:
            print(f"âŒ ë²ˆì—­ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
            return []
    
    def search_multiple_texts(self, texts: List[str], 
                            top_k_per_text: int = 2) -> Dict[str, List[Dict]]:
        """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ì— ëŒ€í•´ ì¼ê´„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        results = {}
        
        for text in texts:
            if text.strip():
                recommendations = self.search_similar_translations(
                    text, 
                    top_k=top_k_per_text
                )
                results[text] = recommendations
            
        return results
    
    def _get_confidence_level(self, similarity_score: float) -> str:
        """ìœ ì‚¬ë„ ì ìˆ˜ì— ë”°ë¥¸ ì‹ ë¢°ë„ ë ˆë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if similarity_score >= 0.8:
            return "ë†’ìŒ"
        elif similarity_score >= 0.6:
            return "ë³´í†µ"
        elif similarity_score >= 0.4:
            return "ë‚®ìŒ"
        else:
            return "ë§¤ìš°ë‚®ìŒ"
    
    def get_stats(self) -> Dict:
        """ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ì˜ í†µê³„ ì •ë³´ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.collection:
            return {"error": "ì»¬ë ‰ì…˜ ì—°ê²° ì‹¤íŒ¨"}
        
        try:
            count = self.collection.count()
            return {
                "total_translations": count,
                "language_pair": self.lang_pair,
                "status": "ì •ìƒ"
            }
        except Exception as e:
            return {"error": str(e)}

# í¸ì˜ í•¨ìˆ˜ë“¤
def search_translation_for_text(text: str, lang_pair: str = "en_ko", 
                               top_k: int = 3) -> List[Dict]:
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ì— ëŒ€í•œ ë²ˆì—­ ì¶”ì²œì„ ìœ„í•œ í¸ì˜ í•¨ìˆ˜"""
    searcher = TranslationSearcher(lang_pair)
    return searcher.search_similar_translations(text, top_k)

def batch_search_translations(texts: List[str], lang_pair: str = "en_ko") -> Dict:
    """ì—¬ëŸ¬ í…ìŠ¤íŠ¸ ì¼ê´„ ê²€ìƒ‰ì„ ìœ„í•œ í¸ì˜ í•¨ìˆ˜"""
    searcher = TranslationSearcher(lang_pair)
    return searcher.search_multiple_texts(texts)

def format_recommendation_for_display(recommendation: Dict) -> str:
    """ì¶”ì²œ ê²°ê³¼ë¥¼ UI í‘œì‹œìš©ìœ¼ë¡œ í¬ë§·íŒ…í•©ë‹ˆë‹¤."""
    confidence_emoji = {
        "ë†’ìŒ": "ğŸŸ¢",
        "ë³´í†µ": "ğŸŸ¡", 
        "ë‚®ìŒ": "ğŸŸ ",
        "ë§¤ìš°ë‚®ìŒ": "ğŸ”´"
    }
    
    emoji = confidence_emoji.get(recommendation['confidence_level'], "âšª")
    similarity = recommendation['similarity_score']
    
    return (
        f"{emoji} **{recommendation['target_text']}** "
        f"(ìœ ì‚¬ë„: {similarity:.1%})\n"
        f"ğŸ“ ì¶œì²˜: `{recommendation['page_path']}`"
    )