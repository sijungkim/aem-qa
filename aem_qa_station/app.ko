import streamlit as st
import pandas as pd
import io
from typing import List, Dict
from modules.connections import get_db
from modules.analyzer import PageAnalyzer, get_text_changes_only
from modules.searcher import TranslationSearcher, format_recommendation_for_display

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(
    page_title="AEM ë²ˆì—­ QA ì›Œí¬ìŠ¤í…Œì´ì…˜",
    page_icon="ğŸ”",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ë©”ì¸ ì œëª©
st.title("ğŸ” AEM ë²ˆì—­ QA ì›Œí¬ìŠ¤í…Œì´ì…˜")
st.markdown("**AI ê¸°ë°˜ í˜ì´ì§€ ë³€ê²½ì‚¬í•­ ë¶„ì„ ë° ë²ˆì—­ ì¶”ì²œ ì‹œìŠ¤í…œ**")

def build_aem_url(page_path: str, version: str, host: str = "https://prod-author.illumina.com") -> str:
    """AEM Author í¸ì§‘ í˜ì´ì§€ URLì„ ìƒì„±í•©ë‹ˆë‹¤."""
    # í˜ì´ì§€ ê²½ë¡œ ì •ë¦¬ (aem_collector.py ë¡œì§ ì°¸ì¡°)
    clean_path = clean_page_path(page_path)
    
    path_templates = {
        # ì˜ì–´
        "lm-en": f"/content/illumina-marketing/language-master/en{clean_path}.html",
        
        # í•œêµ­ì–´
        "lm-ko": f"/content/illumina-marketing/language-master/ko{clean_path}.html",
        "spac-ko_KR": f"/content/illumina-marketing/spac/ko_KR{clean_path}.html",
        
        # ì¼ë³¸ì–´ (ë‚˜ì¤‘ì— ì‚¬ìš©)
        "lm-ja": f"/content/illumina-marketing/language-master/ja{clean_path}.html",
        "apac-ja_JP": f"/content/illumina-marketing/apac/ja_JP{clean_path}.html"
    }
    
    url_path = path_templates.get(version, "")
    if not url_path:
        return ""
    
    # AEM Author í¸ì§‘ URL: host/editor.html + content_path
    return f"{host}/editor.html{url_path}"

def clean_page_path(page_path: str) -> str:
    """í˜ì´ì§€ ê²½ë¡œë¥¼ í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ì •ì œí•©ë‹ˆë‹¤."""
    clean_path = page_path.strip()
    
    # ë‹¤ì–‘í•œ ì ‘ë‘ì‚¬ ì œê±°
    prefixes_to_remove = [
        '/content/illumina-marketing/language-master/en',
        '/content/illumina-marketing/language-master/ko',
        '/content/illumina-marketing/spac/ko_KR',
        '/content/illumina-marketing/en',
        '/content/illumina-marketing/apac/en',
        '/content/illumina-marketing/apac/ja_JP'
    ]
    
    for prefix in prefixes_to_remove:
        if clean_path.startswith(prefix):
            clean_path = clean_path[len(prefix):]
            break
    
    if not clean_path.startswith('/'):
        return '/' + clean_path
    return clean_path

def show_detailed_analysis(page_path: str):
    """ì„ íƒëœ í˜ì´ì§€ì˜ ìƒì„¸ ë¶„ì„ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader(f"ğŸ” ìƒì„¸ ë¶„ì„: {page_path}")
    
    # ê°•ì œë¡œ ë§í¬ ì„¹ì…˜ í‘œì‹œ (í…ŒìŠ¤íŠ¸)
    st.write("---")
    st.write("ğŸ”— **AEM í¸ì§‘ í˜ì´ì§€ ë§í¬**")
    st.write("í…ŒìŠ¤íŠ¸: ì´ í…ìŠ¤íŠ¸ê°€ ë³´ì´ë‚˜ìš”?")
    
    # AEM URL ë§í¬ ìƒì„±
    source_url = build_aem_url(page_path, "lm-en")
    lm_ko_url = build_aem_url(page_path, "lm-ko")
    spac_ko_url = build_aem_url(page_path, "spac-ko_KR")
    
    # URL ì§ì ‘ ì¶œë ¥í•´ì„œ í™•ì¸
    st.write(f"Source URL: {source_url}")
    st.write(f"LM-KO URL: {lm_ko_url}")
    st.write(f"SPAC-KO URL: {spac_ko_url}")
    
    # 3ê°œ ì»¬ëŸ¼ìœ¼ë¡œ ë°°ì¹˜
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.write("**ì†ŒìŠ¤ (ì›ë¬¸)**")
        if source_url:
            st.markdown(f"[ğŸ“ lm-en í¸ì§‘]({source_url})")
        else:
            st.write("âŒ URL ìƒì„± ì‹¤íŒ¨")
    
    with col2:
        st.write("**íƒ€ê²Ÿ (Language Master)**")
        if lm_ko_url:
            st.markdown(f"[ğŸ“ lm-ko í¸ì§‘]({lm_ko_url})")
        else:
            st.write("âŒ URL ìƒì„± ì‹¤íŒ¨")
    
    with col3:
        st.write("**íƒ€ê²Ÿ (SPAC Site)**")
        if spac_ko_url:
            st.markdown(f"[ğŸ“ spac-ko_KR í¸ì§‘]({spac_ko_url})")
        else:
            st.write("âŒ URL ìƒì„± ì‹¤íŒ¨")
    
    st.write("---")
    
    # ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
    analysis = st.session_state.analysis_results.get(page_path)
    if not analysis:
        st.error("ë¶„ì„ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    changes = analysis['changes']
    
    # ìš”ì•½ ì •ë³´
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("ì¶”ê°€ë¨", len(changes['added']))
    with col2:
        st.metric("ìˆ˜ì •ë¨", len(changes['modified']))
    with col3:
        st.metric("ì‚­ì œë¨", len(changes['removed']))
    with col4:
        st.metric("ë³€ê²½ ì—†ìŒ", len(changes['unchanged']))
    
    # í…ìŠ¤íŠ¸ ë³€ê²½ì‚¬í•­ë§Œ í•„í„°ë§
    text_changes = get_text_changes_only(analysis)
    
    if not text_changes:
        st.info("ë²ˆì—­ì´ í•„ìš”í•œ í…ìŠ¤íŠ¸ ë³€ê²½ì‚¬í•­ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # AI ë²ˆì—­ ì¶”ì²œ ì„¹ì…˜
    show_translation_recommendations(text_changes)

def initialize_session_state():
    """ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”"""
    if 'uploaded_pages' not in st.session_state:
        st.session_state.uploaded_pages = []
    if 'selected_page' not in st.session_state:
        st.session_state.selected_page = None
    if 'analysis_results' not in st.session_state:
        st.session_state.analysis_results = {}

def parse_csv_pages(uploaded_file) -> List[str]:
    """ì—…ë¡œë“œëœ CSVì—ì„œ í˜ì´ì§€ URL ëª©ë¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    try:
        df = pd.read_csv(uploaded_file)
        
        # ìš°ì„ ìˆœìœ„ 1: "Page Path" ì»¬ëŸ¼ì´ ìˆëŠ”ì§€ ì •í™•íˆ í™•ì¸
        if 'Page Path' in df.columns:
            pages = df['Page Path'].dropna().unique().tolist()
            st.success(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (ì»¬ëŸ¼: Page Path)")
            return pages
        
        # ìš°ì„ ìˆœìœ„ 2: ëŒ€ì†Œë¬¸ì ë¬´ì‹œí•˜ê³  "page path" ì°¾ê¸°
        page_path_columns = [col for col in df.columns if col.lower() == 'page path']
        if page_path_columns:
            column_name = page_path_columns[0]
            pages = df[column_name].dropna().unique().tolist()
            st.success(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (ì»¬ëŸ¼: {column_name})")
            return pages
        
        # ìš°ì„ ìˆœìœ„ 3: "page"ì™€ "path"ê°€ ëª¨ë‘ í¬í•¨ëœ ì»¬ëŸ¼ ì°¾ê¸°
        page_path_like = [col for col in df.columns if 'page' in col.lower() and 'path' in col.lower()]
        if page_path_like:
            column_name = page_path_like[0]
            pages = df[column_name].dropna().unique().tolist()
            st.success(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤. (ì»¬ëŸ¼: {column_name})")
            return pages
        
        # ìš°ì„ ìˆœìœ„ 4: ê¸°ì¡´ ë¡œì§ - URLì´ í¬í•¨ë  ìˆ˜ ìˆëŠ” ì»¬ëŸ¼ëª…ë“¤ í™•ì¸
        url_columns = [col for col in df.columns if any(
            keyword in col.lower() 
            for keyword in ['url', 'path', 'page', 'link']
        )]
        
        if not url_columns:
            st.error("'Page Path' ë˜ëŠ” URL/í˜ì´ì§€ ê²½ë¡œê°€ í¬í•¨ëœ ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.info("ğŸ’¡ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ëŸ¼ëª…ë“¤:")
            for col in df.columns:
                st.info(f"   - {col}")
            return []
        
        # ì²« ë²ˆì§¸ URL ì»¬ëŸ¼ ì‚¬ìš©
        column_name = url_columns[0]
        pages = df[column_name].dropna().unique().tolist()
        
        st.warning(f"âš ï¸ 'Page Path' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í•´ '{column_name}' ì»¬ëŸ¼ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        st.success(f"âœ… {len(pages)}ê°œì˜ í˜ì´ì§€ë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        return pages
        
    except Exception as e:
        st.error(f"CSV íŒŒì¼ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []

def create_dashboard(pages: List[str]):
    """í˜ì´ì§€ë³„ ë³€ê²½ì‚¬í•­ ìš”ì•½ ëŒ€ì‹œë³´ë“œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    st.subheader("ğŸ“Š í˜ì´ì§€ ë³€ê²½ì‚¬í•­ ëŒ€ì‹œë³´ë“œ")
    
    if not pages:
        st.warning("ë¶„ì„í•  í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    # ì§„í–‰ë¥  í‘œì‹œ
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    dashboard_data = []
    analyzer = PageAnalyzer()
    
    for i, page in enumerate(pages):
        status_text.text(f"ë¶„ì„ ì¤‘: {page}")
        progress_bar.progress((i + 1) / len(pages))
        
        try:
            # ìºì‹œëœ ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ”ì§€ í™•ì¸
            if page not in st.session_state.analysis_results:
                analysis = analyzer.analyze_page_changes(page)
                st.session_state.analysis_results[page] = analysis
            else:
                analysis = st.session_state.analysis_results[page]
            
            summary = analysis['analysis_summary']
            
            # ì „ì²´ ì»´í¬ë„ŒíŠ¸ ìˆ˜ ê³„ì‚°
            total_components = (summary['total_added'] + summary['total_modified'] + 
                              summary['total_removed'] + summary['total_unchanged'])
            
            dashboard_data.append({
                'í˜ì´ì§€ ê²½ë¡œ': page,
                'ì „ì²´': total_components,
                'ì¶”ê°€ë¨': summary['total_added'],
                'ìˆ˜ì •ë¨': summary['total_modified'], 
                'ì‚­ì œë¨': summary['total_removed'],
                'ë³€ê²½ì—†ìŒ': summary['total_unchanged'],
                'ë²ˆì—­ í•„ìš”': summary['needs_translation'],
                'ê²€í†  í•„ìš”': summary['needs_review'],
                'ìƒíƒœ': get_page_status(summary)
            })
            
        except Exception as e:
            dashboard_data.append({
                'í˜ì´ì§€ ê²½ë¡œ': page,
                'ì „ì²´': 0,
                'ì¶”ê°€ë¨': 0, 
                'ìˆ˜ì •ë¨': 0, 
                'ì‚­ì œë¨': 0,
                'ë³€ê²½ì—†ìŒ': 0,
                'ë²ˆì—­ í•„ìš”': 0, 
                'ê²€í†  í•„ìš”': 0,
                'ìƒíƒœ': f"ì˜¤ë¥˜: {str(e)}"
            })
    
    # ê²°ê³¼ í‘œì‹œ
    status_text.text("ë¶„ì„ ì™„ë£Œ!")
    progress_bar.progress(100)
    
    # ëŒ€ì‹œë³´ë“œ í…Œì´ë¸”ì— ì„ íƒ ê¸°ëŠ¥ ì¶”ê°€
    df = pd.DataFrame(dashboard_data)
    
    # ì»¬ëŸ¼ë³„ ì •ë ¬ ë° í•„í„°ë§ ì˜µì…˜
    col1, col2 = st.columns([3, 1])
    
    with col1:
        st.write("ğŸ“Š **í˜ì´ì§€ ë³€ê²½ì‚¬í•­ ìš”ì•½**")
    
    with col2:
        # ìƒíƒœ í•„í„°
        status_filter = st.selectbox(
            "ìƒíƒœ í•„í„°:",
            ["ì „ì²´", "ë²ˆì—­ í•„ìš”", "ë³€ê²½ì‚¬í•­ ìˆìŒ", "ë³€ê²½ ì—†ìŒ"],
            key="status_filter"
        )
    
    # í•„í„°ë§ ì ìš©
    if status_filter != "ì „ì²´":
        if status_filter == "ë²ˆì—­ í•„ìš”":
            df = df[df['ìƒíƒœ'].str.contains('ë²ˆì—­ í•„ìš”')]
        elif status_filter == "ë³€ê²½ì‚¬í•­ ìˆìŒ":
            df = df[df['ìƒíƒœ'].str.contains('ë³€ê²½ì‚¬í•­ ìˆìŒ')]
        elif status_filter == "ë³€ê²½ ì—†ìŒ":
            df = df[df['ìƒíƒœ'].str.contains('ë³€ê²½ ì—†ìŒ')]
    
    # í…Œì´ë¸”ê³¼ ì„ íƒ ë²„íŠ¼ì„ í•¨ê»˜ í‘œì‹œ
    if not df.empty:
        # ì„ íƒëœ í˜ì´ì§€ë¥¼ ì €ì¥í•  ì„¸ì…˜ ìƒíƒœ
        if 'selected_page_for_detail' not in st.session_state:
            st.session_state.selected_page_for_detail = None
        
        # ê° í–‰ë§ˆë‹¤ ì„ íƒ ë²„íŠ¼ê³¼ í•¨ê»˜ í‘œì‹œ
        for idx, row in df.iterrows():
            page_path = row['í˜ì´ì§€ ê²½ë¡œ']
            status = row['ìƒíƒœ']
            total = row['ì „ì²´']
            added = row['ì¶”ê°€ë¨']
            modified = row['ìˆ˜ì •ë¨']
            deleted = row['ì‚­ì œë¨']
            unchanged = row['ë³€ê²½ì—†ìŒ']
            
            with st.container():
                col1, col2 = st.columns([6, 1])
                
                with col1:
                    # ì§§ì€ í˜ì´ì§€ ê²½ë¡œ í‘œì‹œ (í…Œì´ë¸”ìš©)
                    short_path = page_path.replace('/content/illumina-marketing/en', '...')
                    
                    # ë³€ê²½ì‚¬í•­ ë¹„ìœ¨ ê³„ì‚°
                    changed_count = added + modified + deleted
                    change_percentage = (changed_count / total * 100) if total > 0 else 0
                    
                    # Option 5 ìŠ¤íƒ€ì¼: ê¹”ë”í•œ ì—¬ëŸ¬ ì¤„ í‘œì‹œ
                    st.write(f"**{short_path}**")
                    st.write(f"{status}")
                    st.write("")  # ì‘ì€ ê°„ê²©
                    
                    # ì•„ì´ì½˜ + ìƒ‰ìƒ ì¡°í•© ì •ë³´ ë¼ì¸
                    info_parts = []
                    if total > 0:
                        info_parts.append(f"ğŸ“Š ì „ì²´ {total}ê°œ")
                    if unchanged > 0:
                        info_parts.append(f"ğŸŸ¢ ë³€ê²½ì—†ìŒ {unchanged}ê°œ")
                    if modified > 0:
                        info_parts.append(f"ğŸŸ¡ ìˆ˜ì •ë¨ {modified}ê°œ")
                    if added > 0:
                        info_parts.append(f"ğŸŸ¢ ì¶”ê°€ë¨ {added}ê°œ")
                    if deleted > 0:
                        info_parts.append(f"ğŸ”´ ì‚­ì œë¨ {deleted}ê°œ")
                    if change_percentage > 0:
                        info_parts.append(f"ğŸ“ˆ ë³€ê²½ë¥  {change_percentage:.1f}%")
                    
                    if info_parts:
                        st.write("  |  ".join(info_parts))
                
                with col2:
                    # í† ê¸€ ë²„íŠ¼ (ì—´ê¸°/ë‹«ê¸°)
                    current_selected = st.session_state.selected_page_for_detail == page_path
                    button_text = "ğŸ“¤ ë‹«ê¸°" if current_selected else "ğŸ“‹ ìƒì„¸"
                    
                    if st.button(button_text, key=f"detail_btn_{idx}"):
                        if current_selected:
                            # ì´ë¯¸ ì„ íƒëœ í˜ì´ì§€ë©´ ë‹«ê¸°
                            st.session_state.selected_page_for_detail = None
                        else:
                            # ìƒˆë¡œìš´ í˜ì´ì§€ ì„ íƒ
                            st.session_state.selected_page_for_detail = page_path
                        st.rerun()
                
                # ì´ í–‰ì´ ì„ íƒë˜ì—ˆìœ¼ë©´ ë°”ë¡œ ì•„ë˜ì— ìƒì„¸ ë¶„ì„ í‘œì‹œ
                if st.session_state.selected_page_for_detail == page_path:
                    with st.expander("ğŸ“Š ìƒì„¸ ë¶„ì„", expanded=True):
                        show_detailed_analysis(page_path)
                
                st.divider()
    
    else:
        st.info("í•„í„° ì¡°ê±´ì— ë§ëŠ” í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")

def get_page_status(summary: Dict) -> str:
    """í˜ì´ì§€ ìƒíƒœë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
    if summary['needs_translation'] > 0 or summary['needs_review'] > 0:
        return f"ğŸŸ¡ ë²ˆì—­ í•„ìš” ({summary['needs_translation']}ê°œ)"
    elif summary['total_added'] + summary['total_modified'] + summary['total_removed'] > 0:
        return "ğŸŸ  ë³€ê²½ì‚¬í•­ ìˆìŒ"
    else:
        return "ğŸŸ¢ ë³€ê²½ ì—†ìŒ"

def show_translation_recommendations(text_changes: List[Dict]):
    """AI ë²ˆì—­ ì¶”ì²œì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    st.subheader("ğŸ¤– AI ë²ˆì—­ ì¶”ì²œ")
    
    # ì–¸ì–´ ìŒ ì„ íƒ
    language_options = {
        "ì˜ì–´ â†’ í•œêµ­ì–´": "en_ko",
        "ì˜ì–´ â†’ ì¼ë³¸ì–´": "en_ja"
    }
    
    selected_lang = st.selectbox(
        "ì–¸ì–´ ìŒ ì„ íƒ:",
        options=list(language_options.keys())
    )
    
    lang_pair = language_options[selected_lang]
    
    # Translation Searcher ì´ˆê¸°í™”
    with st.spinner("AI ëª¨ë¸ ë¡œë”© ì¤‘..."):
        try:
            searcher = TranslationSearcher(lang_pair)
            
            # GPU ìƒíƒœ í‘œì‹œ
            stats = searcher.get_stats()
            if "error" not in stats:
                st.success(f"ğŸš€ GPU ê°€ì† AI ëª¨ë¸ ì¤€ë¹„ ì™„ë£Œ! (DB: {stats['total_translations']:,}ê°œ ë²ˆì—­ ì‚¬ë¡€)")
            else:
                st.error(f"ë²ˆì—­ DB ì—°ê²° ì‹¤íŒ¨: {stats['error']}")
                return
                
        except Exception as e:
            st.error(f"AI ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            return
    
    # ê° ë³€ê²½ì‚¬í•­ì— ëŒ€í•œ ë²ˆì—­ ì¶”ì²œ
    for i, change in enumerate(text_changes):
        with st.expander(f"ğŸ“ ë³€ê²½ì‚¬í•­ {i+1}: {change['component_path']}", expanded=True):
            
            # ë³€ê²½ ë‚´ìš© í‘œì‹œ
            if change['change_type'] == 'added':
                st.write("**ğŸ†• ìƒˆë¡œ ì¶”ê°€ëœ í…ìŠ¤íŠ¸:**")
                st.code(change['content'], language='text')
                search_text = change['content']
                
            elif change['change_type'] == 'modified':
                st.write("**âœï¸ ìˆ˜ì •ëœ í…ìŠ¤íŠ¸:**")
                col1, col2 = st.columns(2)
                with col1:
                    st.write("*ì†ŒìŠ¤ (ì›ë¬¸):*")
                    st.code(change['source_content'], language='text')
                with col2:
                    st.write("*íƒ€ê²Ÿ (ë²ˆì—­ë¬¸):*")
                    st.code(change['target_content'], language='text')
                search_text = change['source_content']
            
            # AI ë²ˆì—­ ì¶”ì²œ
            if search_text.strip():
                with st.spinner("AIê°€ ë²ˆì—­ì„ ì°¾ê³  ìˆìŠµë‹ˆë‹¤..."):
                    recommendations = searcher.search_similar_translations(search_text, top_k=3)
                
                if recommendations:
                    st.write("**ğŸ¤– AI ì¶”ì²œ ë²ˆì—­:**")
                    
                    for j, rec in enumerate(recommendations):
                        recommendation_text = format_recommendation_for_display(rec)
                        st.markdown(f"**{j+1}.** {recommendation_text}")
                        
                        # ìƒì„¸ ì •ë³´ (ì ‘ì„ ìˆ˜ ìˆìŒ)
                        with st.expander(f"ìƒì„¸ ì •ë³´ {j+1}", expanded=False):
                            st.write(f"**ì›ë¬¸:** {rec['source_text']}")
                            st.write(f"**ë²ˆì—­:** {rec['target_text']}")
                            st.write(f"**ìœ ì‚¬ë„:** {rec['similarity_score']:.1%}")
                            st.write(f"**ì‹ ë¢°ë„:** {rec['confidence_level']}")
                            
                            # spac-ko_KR í˜ì´ì§€ ê²½ë¡œ ìƒì„±
                            source_page_path = rec['page_path']
                            target_page_url = build_aem_url(source_page_path, "spac-ko_KR")
                            
                            st.write(f"**ì¶œì²˜ í˜ì´ì§€:** {source_page_path}")
                            if target_page_url:
                                st.markdown(f"**í•œêµ­ì–´ í˜ì´ì§€:** [spac-ko_KRì—ì„œ ë³´ê¸°]({target_page_url})")
                            st.write(f"**ì»´í¬ë„ŒíŠ¸ ê²½ë¡œ:** {rec['component_path']}")
                            
                            # í˜„ì¬ ë³€ê²½ì‚¬í•­ì˜ ì»´í¬ë„ŒíŠ¸ ì •ë³´ë„ í‘œì‹œ
                            if 'component_path' in change:
                                st.write("---")
                                st.write("**í˜„ì¬ ë³€ê²½ì‚¬í•­:**")
                                st.write(f"**ì»´í¬ë„ŒíŠ¸ ê²½ë¡œ:** {change['component_path']}")
                                if 'component_type' in change and change['component_type']:
                                    st.write(f"**ì»´í¬ë„ŒíŠ¸ íƒ€ì…:** {change['component_type']}")
                else:
                    st.warning("ğŸ” ìœ ì‚¬í•œ ë²ˆì—­ ì‚¬ë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

def main():
    """ë©”ì¸ ì•± ë¡œì§"""
    initialize_session_state()
    
    # ì‚¬ì´ë“œë°”: íŒŒì¼ ì—…ë¡œë“œ
    with st.sidebar:
        st.header("ğŸ“ íŒŒì¼ ì—…ë¡œë“œ")
        uploaded_file = st.file_uploader(
            "ê²€ìˆ˜í•  í˜ì´ì§€ ëª©ë¡ CSVë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”",
            type=['csv'],
            help="Page Path ì»¬ëŸ¼ì´ í¬í•¨ëœ CSV íŒŒì¼"
        )
        
        if uploaded_file is not None:
            # CSV íŒŒì‹±
            pages = parse_csv_pages(uploaded_file)
            st.session_state.uploaded_pages = pages
            
        # ì—°ê²° ìƒíƒœ í™•ì¸
        st.header("ğŸ”Œ ì—°ê²° ìƒíƒœ")
        try:
            db = get_db()
            collections = db.list_collection_names()
            st.success(f"âœ… MongoDB ì—°ê²°ë¨ ({len(collections)}ê°œ ì»¬ë ‰ì…˜)")
        except Exception as e:
            st.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {str(e)}")
    
    # ë©”ì¸ í™”ë©´
    if not st.session_state.uploaded_pages:
        st.info("ğŸ‘ˆ ì‚¬ì´ë“œë°”ì—ì„œ CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”.")
        
        # ìƒ˜í”Œ CSV í˜•ì‹ ì•ˆë‚´
        st.subheader("ğŸ“‹ CSV íŒŒì¼ í˜•ì‹ ì˜ˆì‹œ")
        sample_data = {
            'Page Path': [
                '/content/illumina-marketing/en/products/sequencing',
                '/content/illumina-marketing/en/areas-of-interest/cancer',
                '/content/illumina-marketing/en/company/news'
            ],
            'Status': ['ê²€í†  í•„ìš”', 'ë²ˆì—­ í•„ìš”', 'ì™„ë£Œ'],
            'Priority': ['High', 'Medium', 'Low']
        }
        st.dataframe(pd.DataFrame(sample_data))
        st.info("ğŸ’¡ **'Page Path'** ì»¬ëŸ¼ëª…ì„ ì‚¬ìš©í•˜ë©´ ìë™ìœ¼ë¡œ ì¸ì‹ë©ë‹ˆë‹¤.")
        
    else:
        # ëŒ€ì‹œë³´ë“œ í‘œì‹œ
        create_dashboard(st.session_state.uploaded_pages)

if __name__ == "__main__":
    main()